{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smnd/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2fe12239fe0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ...? drop out?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             valid_acc = sess.run(accuracy, feed_dict={\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# My own Convolutional Neural Network\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Importing MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.000001\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "valid_data_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10\n",
    "dropout = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- def Xavier_initializer -------------------- #\n",
    "def Xavier_init(name, shape_in):\n",
    "    return tf.get_variable(name, shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())\n",
    "# ---------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# Store Weights & Bias\n",
    "weights = {\n",
    "    'wc1': Xavier_init('wc1',[5, 5, 1, 32]),\n",
    "    'wc2': Xavier_init('wc2',[5, 5, 32, 64]),\n",
    "    'w1' : Xavier_init('w1',[7*7*64, 1024]), # 7*7*64\n",
    "    'w2' : Xavier_init('w2',[1024, 1024]),\n",
    "    'wout': Xavier_init('wout',[1024, n_classes])\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': Xavier_init('bc1',[32]),\n",
    "    'bc2': Xavier_init('bc2',[64]),\n",
    "    'b1' : Xavier_init('b1',[1024]),\n",
    "    'b2' : Xavier_init('b2',[1024]),\n",
    "    'bout': Xavier_init('bout',[n_classes])\n",
    "}\n",
    "\n",
    "# ------------------------- defining functions ----------------------- #\n",
    "# Convolution layer\n",
    "def conv2d(x, W, b, strides=1):                                         # stride = 1\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Pooling\n",
    "def maxpool2d(x, k=2):                                                  # patch size = 2\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')\n",
    "\n",
    "# Convolution + Pooling + hidden layer\n",
    "def conv_net(x,weights, biases, dropout):\n",
    "    # Convolution Layer #1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Convolution Layer #2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    \n",
    "    # Hidden Layer #1\n",
    "    hl1 = tf.reshape(conv2, [-1, weights['w1'].get_shape().as_list()[0]])\n",
    "    hl1 = tf.add(tf.matmul(hl1, weights['w1']), biases['b1'])\n",
    "    hl1 = tf.nn.relu(hl1)\n",
    "    hl1 = tf.nn.dropout(hl1, dropout)\n",
    "    \n",
    "  \n",
    "    # Hidden Layer #2\n",
    "    # hl2 = tf.reshape(hl1, [-1, weights['w2'].get_shape().as_list()[0]])\n",
    "    hl2 = tf.add(tf.matmul(hl1, weights['w2']), biases['b2'])\n",
    "    hl2 = tf.nn.relu(hl2)\n",
    "    hl2 = tf.nn.dropout(hl2, dropout)\n",
    "    \n",
    "    # Output Layer\n",
    "    out = tf.add(tf.matmul(hl2, weights['wout']), biases['bout'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return out, conv1, conv2, hl1, hl2\n",
    " \n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# input & output placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob_dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# Model : output\n",
    "logits, conv1, conv2, fc1, fc2  = conv_net(x, weights, biases, keep_prob_dropout)\n",
    "\n",
    "# Define loss & Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1)) # 1???? test later\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver\n",
    "save_file = './SaveData/test1.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Training start\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}) # ...? drop out?\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob_dropout: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:valid_data_size],\n",
    "                y: mnist.validation.labels[:valid_data_size],\n",
    "                keep_prob_dropout: 1.})\n",
    "            # print('Epoch = {:}, Batch = {:}, loss = {:.5f}, accuracy = {:.5f}'.format(epoch+1, batch+1, loss, valid_acc))\n",
    "            \n",
    "            # for debugging\n",
    "            # print(sess.run(logits, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}))\n",
    "            # conv11, conv21, fc11, fc21 = sess.run([conv1, conv2, fc1, fc2], feed_dict = {x:batch_x, y:batch_y, keep_prob_dropout: dropout})\n",
    "            # print(sess.run(logits, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}))\n",
    "            # print(np.any(np.isinf(conv11)),np.any(np.isnan(conv11)))\n",
    "            # print(np.any(np.isinf(conv21)),np.any(np.isnan(conv21)))\n",
    "            # print(np.any(np.isinf(fc11)),np.any(np.isnan(fc11)))\n",
    "            # print(np.any(np.isinf(fc21)),np.any(np.isnan(fc21)))\n",
    "        \n",
    "        print('Epoch = {:}, Batch = {:}, loss = {:.5f}, accuracy = {:.5f}'.format(epoch+1, batch+1, loss, valid_acc))\n",
    "        #saver.save(sess, save_file)\n",
    "    print('fuck')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smnd/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from ./SaveData/test1.ckpt\n",
      "Epoch = 1, Batch = 429, loss = 0.26446, accuracy = 0.92188\n",
      "Epoch = 2, Batch = 429, loss = 0.24743, accuracy = 0.92188\n",
      "Epoch = 3, Batch = 429, loss = 0.24046, accuracy = 0.92188\n",
      "Epoch = 4, Batch = 429, loss = 0.28994, accuracy = 0.92188\n",
      "Epoch = 5, Batch = 429, loss = 0.26842, accuracy = 0.92188\n",
      "Epoch = 6, Batch = 429, loss = 0.24339, accuracy = 0.92578\n",
      "Epoch = 7, Batch = 429, loss = 0.13569, accuracy = 0.92578\n",
      "Epoch = 8, Batch = 429, loss = 0.19755, accuracy = 0.92578\n",
      "Epoch = 9, Batch = 429, loss = 0.20549, accuracy = 0.92578\n",
      "Epoch = 10, Batch = 429, loss = 0.28872, accuracy = 0.92188\n",
      "Epoch = 11, Batch = 429, loss = 0.21335, accuracy = 0.92578\n",
      "Epoch = 12, Batch = 429, loss = 0.15247, accuracy = 0.92969\n",
      "Epoch = 13, Batch = 429, loss = 0.24080, accuracy = 0.92578\n",
      "Epoch = 14, Batch = 429, loss = 0.16467, accuracy = 0.92578\n",
      "Epoch = 15, Batch = 429, loss = 0.20158, accuracy = 0.92969\n",
      "Epoch = 16, Batch = 429, loss = 0.14495, accuracy = 0.92969\n",
      "Epoch = 17, Batch = 429, loss = 0.11571, accuracy = 0.92969\n",
      "Epoch = 18, Batch = 429, loss = 0.16818, accuracy = 0.92969\n",
      "Epoch = 19, Batch = 429, loss = 0.22984, accuracy = 0.92969\n",
      "Epoch = 20, Batch = 429, loss = 0.06257, accuracy = 0.92969\n",
      "Epoch = 21, Batch = 429, loss = 0.28085, accuracy = 0.92969\n",
      "Epoch = 22, Batch = 429, loss = 0.15724, accuracy = 0.92969\n",
      "Epoch = 23, Batch = 429, loss = 0.19375, accuracy = 0.92969\n",
      "Epoch = 24, Batch = 429, loss = 0.19796, accuracy = 0.92969\n",
      "Epoch = 25, Batch = 429, loss = 0.26912, accuracy = 0.92969\n",
      "Epoch = 26, Batch = 429, loss = 0.13498, accuracy = 0.92969\n",
      "Epoch = 27, Batch = 429, loss = 0.12612, accuracy = 0.93359\n",
      "Epoch = 28, Batch = 429, loss = 0.14384, accuracy = 0.92969\n",
      "Epoch = 29, Batch = 429, loss = 0.09066, accuracy = 0.93359\n",
      "Epoch = 30, Batch = 429, loss = 0.10600, accuracy = 0.92969\n",
      "Epoch = 31, Batch = 429, loss = 0.09369, accuracy = 0.93359\n",
      "Epoch = 32, Batch = 429, loss = 0.09876, accuracy = 0.93359\n",
      "Epoch = 33, Batch = 429, loss = 0.17606, accuracy = 0.93750\n",
      "Epoch = 34, Batch = 429, loss = 0.12512, accuracy = 0.93359\n",
      "Epoch = 35, Batch = 429, loss = 0.11640, accuracy = 0.93750\n",
      "Epoch = 36, Batch = 429, loss = 0.09722, accuracy = 0.93750\n",
      "Epoch = 37, Batch = 429, loss = 0.17500, accuracy = 0.94141\n",
      "Epoch = 38, Batch = 429, loss = 0.14045, accuracy = 0.94141\n",
      "Epoch = 39, Batch = 429, loss = 0.15578, accuracy = 0.94531\n",
      "Epoch = 40, Batch = 429, loss = 0.20383, accuracy = 0.94141\n",
      "Epoch = 41, Batch = 429, loss = 0.16019, accuracy = 0.94141\n",
      "Epoch = 42, Batch = 429, loss = 0.22157, accuracy = 0.94922\n",
      "Epoch = 43, Batch = 429, loss = 0.22496, accuracy = 0.94531\n",
      "Epoch = 44, Batch = 429, loss = 0.08074, accuracy = 0.94922\n",
      "Epoch = 45, Batch = 429, loss = 0.06626, accuracy = 0.94922\n",
      "Epoch = 46, Batch = 429, loss = 0.12633, accuracy = 0.95312\n",
      "Epoch = 47, Batch = 429, loss = 0.12229, accuracy = 0.95703\n",
      "Epoch = 48, Batch = 429, loss = 0.27159, accuracy = 0.95312\n",
      "Epoch = 49, Batch = 429, loss = 0.21657, accuracy = 0.95312\n",
      "Epoch = 50, Batch = 429, loss = 0.25168, accuracy = 0.95312\n",
      "Epoch = 51, Batch = 429, loss = 0.05199, accuracy = 0.94922\n",
      "Epoch = 52, Batch = 429, loss = 0.22212, accuracy = 0.94922\n",
      "Epoch = 53, Batch = 429, loss = 0.09410, accuracy = 0.95312\n",
      "Epoch = 54, Batch = 429, loss = 0.13881, accuracy = 0.95312\n",
      "Epoch = 55, Batch = 429, loss = 0.25330, accuracy = 0.95703\n",
      "Epoch = 56, Batch = 429, loss = 0.15933, accuracy = 0.95703\n",
      "Epoch = 57, Batch = 429, loss = 0.09456, accuracy = 0.95312\n",
      "Epoch = 58, Batch = 429, loss = 0.06813, accuracy = 0.94531\n",
      "Epoch = 59, Batch = 429, loss = 0.20868, accuracy = 0.95312\n",
      "Epoch = 60, Batch = 429, loss = 0.09281, accuracy = 0.95312\n",
      "Epoch = 61, Batch = 429, loss = 0.14233, accuracy = 0.96094\n",
      "Epoch = 62, Batch = 429, loss = 0.05119, accuracy = 0.95703\n",
      "Epoch = 63, Batch = 429, loss = 0.19544, accuracy = 0.96094\n",
      "Epoch = 64, Batch = 429, loss = 0.15281, accuracy = 0.96094\n",
      "Epoch = 65, Batch = 429, loss = 0.16631, accuracy = 0.95703\n",
      "Epoch = 66, Batch = 429, loss = 0.10619, accuracy = 0.95703\n",
      "Epoch = 67, Batch = 429, loss = 0.11005, accuracy = 0.96484\n",
      "Epoch = 68, Batch = 429, loss = 0.12185, accuracy = 0.96484\n",
      "Epoch = 69, Batch = 429, loss = 0.05048, accuracy = 0.96094\n",
      "Epoch = 70, Batch = 429, loss = 0.08824, accuracy = 0.95703\n",
      "Epoch = 71, Batch = 429, loss = 0.03784, accuracy = 0.96094\n",
      "Epoch = 72, Batch = 429, loss = 0.06612, accuracy = 0.96094\n",
      "Epoch = 73, Batch = 429, loss = 0.09471, accuracy = 0.96094\n",
      "Epoch = 74, Batch = 429, loss = 0.06445, accuracy = 0.96094\n",
      "Epoch = 75, Batch = 429, loss = 0.06723, accuracy = 0.96094\n",
      "Epoch = 76, Batch = 429, loss = 0.05782, accuracy = 0.96484\n",
      "Epoch = 77, Batch = 429, loss = 0.10240, accuracy = 0.96484\n",
      "Epoch = 78, Batch = 429, loss = 0.05204, accuracy = 0.96484\n",
      "Epoch = 79, Batch = 429, loss = 0.09823, accuracy = 0.96484\n",
      "Epoch = 80, Batch = 429, loss = 0.09732, accuracy = 0.96484\n",
      "Epoch = 81, Batch = 429, loss = 0.28502, accuracy = 0.96484\n",
      "Epoch = 82, Batch = 429, loss = 0.14126, accuracy = 0.96484\n",
      "Epoch = 83, Batch = 429, loss = 0.12462, accuracy = 0.96484\n",
      "Epoch = 84, Batch = 429, loss = 0.07719, accuracy = 0.96484\n",
      "Epoch = 85, Batch = 429, loss = 0.13670, accuracy = 0.96875\n",
      "Epoch = 86, Batch = 429, loss = 0.13871, accuracy = 0.96484\n",
      "Epoch = 87, Batch = 429, loss = 0.08863, accuracy = 0.96484\n",
      "Epoch = 88, Batch = 429, loss = 0.03818, accuracy = 0.96484\n",
      "Epoch = 89, Batch = 429, loss = 0.06512, accuracy = 0.96484\n",
      "Epoch = 90, Batch = 429, loss = 0.07645, accuracy = 0.96484\n",
      "Epoch = 91, Batch = 429, loss = 0.09341, accuracy = 0.96484\n",
      "Epoch = 92, Batch = 429, loss = 0.06107, accuracy = 0.96875\n",
      "Epoch = 93, Batch = 429, loss = 0.14002, accuracy = 0.96875\n",
      "Epoch = 94, Batch = 429, loss = 0.22203, accuracy = 0.96875\n",
      "Epoch = 95, Batch = 429, loss = 0.03545, accuracy = 0.96875\n",
      "Epoch = 96, Batch = 429, loss = 0.07279, accuracy = 0.96875\n",
      "Epoch = 97, Batch = 429, loss = 0.03627, accuracy = 0.96875\n",
      "Epoch = 98, Batch = 429, loss = 0.12188, accuracy = 0.96875\n",
      "Epoch = 99, Batch = 429, loss = 0.05761, accuracy = 0.96875\n",
      "Epoch = 100, Batch = 429, loss = 0.12545, accuracy = 0.96875\n",
      "Epoch = 101, Batch = 429, loss = 0.07818, accuracy = 0.96875\n",
      "Epoch = 102, Batch = 429, loss = 0.07039, accuracy = 0.96875\n",
      "Epoch = 103, Batch = 429, loss = 0.06987, accuracy = 0.96875\n",
      "Epoch = 104, Batch = 429, loss = 0.13086, accuracy = 0.96875\n",
      "Epoch = 105, Batch = 429, loss = 0.10869, accuracy = 0.96875\n",
      "Epoch = 106, Batch = 429, loss = 0.04109, accuracy = 0.96875\n",
      "Epoch = 107, Batch = 429, loss = 0.07974, accuracy = 0.96875\n",
      "Epoch = 108, Batch = 429, loss = 0.07901, accuracy = 0.96875\n",
      "Epoch = 109, Batch = 429, loss = 0.03279, accuracy = 0.96875\n",
      "Epoch = 110, Batch = 429, loss = 0.11102, accuracy = 0.96875\n",
      "Epoch = 111, Batch = 429, loss = 0.06089, accuracy = 0.96875\n",
      "Epoch = 112, Batch = 429, loss = 0.10988, accuracy = 0.96875\n",
      "Epoch = 113, Batch = 429, loss = 0.10567, accuracy = 0.96875\n",
      "Epoch = 114, Batch = 429, loss = 0.08223, accuracy = 0.96875\n",
      "Epoch = 115, Batch = 429, loss = 0.03148, accuracy = 0.96875\n",
      "Epoch = 116, Batch = 429, loss = 0.03349, accuracy = 0.96875\n",
      "Epoch = 117, Batch = 429, loss = 0.03239, accuracy = 0.96875\n",
      "Epoch = 118, Batch = 429, loss = 0.05342, accuracy = 0.96875\n",
      "Epoch = 119, Batch = 429, loss = 0.11203, accuracy = 0.96875\n",
      "Epoch = 120, Batch = 429, loss = 0.06088, accuracy = 0.96875\n",
      "Epoch = 121, Batch = 429, loss = 0.09332, accuracy = 0.96875\n",
      "Epoch = 122, Batch = 429, loss = 0.17904, accuracy = 0.96875\n",
      "Epoch = 123, Batch = 429, loss = 0.08931, accuracy = 0.96875\n",
      "Epoch = 124, Batch = 429, loss = 0.02587, accuracy = 0.96875\n",
      "Epoch = 125, Batch = 429, loss = 0.05778, accuracy = 0.96875\n",
      "Epoch = 126, Batch = 429, loss = 0.03812, accuracy = 0.96875\n",
      "Epoch = 127, Batch = 429, loss = 0.08353, accuracy = 0.96875\n",
      "Epoch = 128, Batch = 429, loss = 0.11343, accuracy = 0.96875\n",
      "Epoch = 129, Batch = 429, loss = 0.07406, accuracy = 0.96875\n",
      "Epoch = 130, Batch = 429, loss = 0.05221, accuracy = 0.96875\n",
      "Epoch = 131, Batch = 429, loss = 0.09626, accuracy = 0.96875\n",
      "Epoch = 132, Batch = 429, loss = 0.08045, accuracy = 0.96875\n",
      "Epoch = 133, Batch = 429, loss = 0.09685, accuracy = 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 134, Batch = 429, loss = 0.06296, accuracy = 0.96875\n",
      "Epoch = 135, Batch = 429, loss = 0.02481, accuracy = 0.96875\n",
      "Epoch = 136, Batch = 429, loss = 0.11471, accuracy = 0.96875\n",
      "Epoch = 137, Batch = 429, loss = 0.08539, accuracy = 0.96875\n",
      "Epoch = 138, Batch = 429, loss = 0.08459, accuracy = 0.96875\n",
      "Epoch = 139, Batch = 429, loss = 0.05398, accuracy = 0.96875\n",
      "Epoch = 140, Batch = 429, loss = 0.07785, accuracy = 0.96875\n",
      "Epoch = 141, Batch = 429, loss = 0.04470, accuracy = 0.97266\n",
      "Epoch = 142, Batch = 429, loss = 0.12198, accuracy = 0.97266\n",
      "Epoch = 143, Batch = 429, loss = 0.08166, accuracy = 0.97266\n",
      "Epoch = 144, Batch = 429, loss = 0.04841, accuracy = 0.96875\n",
      "Epoch = 145, Batch = 429, loss = 0.03980, accuracy = 0.97266\n",
      "Epoch = 146, Batch = 429, loss = 0.04576, accuracy = 0.97266\n",
      "Epoch = 147, Batch = 429, loss = 0.13336, accuracy = 0.97266\n",
      "Epoch = 148, Batch = 429, loss = 0.14209, accuracy = 0.96875\n",
      "Epoch = 149, Batch = 429, loss = 0.02905, accuracy = 0.97266\n",
      "Epoch = 150, Batch = 429, loss = 0.05996, accuracy = 0.96875\n",
      "Epoch = 151, Batch = 429, loss = 0.05680, accuracy = 0.96875\n",
      "Epoch = 152, Batch = 429, loss = 0.08794, accuracy = 0.96875\n",
      "Epoch = 153, Batch = 429, loss = 0.09622, accuracy = 0.97266\n",
      "Epoch = 154, Batch = 429, loss = 0.03832, accuracy = 0.97266\n",
      "Epoch = 155, Batch = 429, loss = 0.09395, accuracy = 0.97266\n",
      "Epoch = 156, Batch = 429, loss = 0.07390, accuracy = 0.97266\n",
      "Epoch = 157, Batch = 429, loss = 0.09674, accuracy = 0.97266\n",
      "Epoch = 158, Batch = 429, loss = 0.06317, accuracy = 0.97266\n",
      "Epoch = 159, Batch = 429, loss = 0.05194, accuracy = 0.97266\n",
      "Epoch = 160, Batch = 429, loss = 0.06402, accuracy = 0.97266\n",
      "Epoch = 161, Batch = 429, loss = 0.07524, accuracy = 0.97266\n",
      "Epoch = 162, Batch = 429, loss = 0.03108, accuracy = 0.97266\n",
      "Epoch = 163, Batch = 429, loss = 0.02914, accuracy = 0.97266\n",
      "Epoch = 164, Batch = 429, loss = 0.02802, accuracy = 0.97266\n",
      "Epoch = 165, Batch = 429, loss = 0.10432, accuracy = 0.97266\n",
      "Epoch = 166, Batch = 429, loss = 0.01498, accuracy = 0.97266\n",
      "Epoch = 167, Batch = 429, loss = 0.09620, accuracy = 0.97266\n",
      "Epoch = 168, Batch = 429, loss = 0.07223, accuracy = 0.97266\n",
      "Epoch = 169, Batch = 429, loss = 0.04789, accuracy = 0.97266\n",
      "Epoch = 170, Batch = 429, loss = 0.04121, accuracy = 0.97266\n",
      "Epoch = 171, Batch = 429, loss = 0.12059, accuracy = 0.97266\n",
      "Epoch = 172, Batch = 429, loss = 0.06371, accuracy = 0.97266\n",
      "Epoch = 173, Batch = 429, loss = 0.07807, accuracy = 0.97266\n",
      "Epoch = 174, Batch = 429, loss = 0.04927, accuracy = 0.97266\n",
      "Epoch = 175, Batch = 429, loss = 0.03290, accuracy = 0.97266\n",
      "Epoch = 176, Batch = 429, loss = 0.05227, accuracy = 0.97266\n",
      "Epoch = 177, Batch = 429, loss = 0.05874, accuracy = 0.97266\n",
      "Epoch = 178, Batch = 429, loss = 0.02253, accuracy = 0.96875\n",
      "Epoch = 179, Batch = 429, loss = 0.05449, accuracy = 0.97266\n",
      "Epoch = 180, Batch = 429, loss = 0.02212, accuracy = 0.97266\n",
      "Epoch = 181, Batch = 429, loss = 0.04109, accuracy = 0.97266\n",
      "Epoch = 182, Batch = 429, loss = 0.04302, accuracy = 0.97266\n",
      "Epoch = 183, Batch = 429, loss = 0.03158, accuracy = 0.97266\n",
      "Epoch = 184, Batch = 429, loss = 0.07352, accuracy = 0.97266\n",
      "Epoch = 185, Batch = 429, loss = 0.03859, accuracy = 0.97266\n",
      "Epoch = 186, Batch = 429, loss = 0.01527, accuracy = 0.97266\n",
      "Epoch = 187, Batch = 429, loss = 0.03124, accuracy = 0.97266\n",
      "Epoch = 188, Batch = 429, loss = 0.05432, accuracy = 0.97266\n",
      "Epoch = 189, Batch = 429, loss = 0.10564, accuracy = 0.97266\n",
      "Epoch = 190, Batch = 429, loss = 0.05251, accuracy = 0.96875\n",
      "Epoch = 191, Batch = 429, loss = 0.00618, accuracy = 0.97266\n",
      "Epoch = 192, Batch = 429, loss = 0.05031, accuracy = 0.97266\n",
      "Epoch = 193, Batch = 429, loss = 0.04877, accuracy = 0.97266\n",
      "Epoch = 194, Batch = 429, loss = 0.03571, accuracy = 0.96875\n",
      "Epoch = 195, Batch = 429, loss = 0.07300, accuracy = 0.96875\n",
      "Epoch = 196, Batch = 429, loss = 0.03578, accuracy = 0.96875\n",
      "Epoch = 197, Batch = 429, loss = 0.01280, accuracy = 0.97266\n",
      "Epoch = 198, Batch = 429, loss = 0.03332, accuracy = 0.96875\n",
      "Epoch = 199, Batch = 429, loss = 0.06132, accuracy = 0.96875\n",
      "Epoch = 200, Batch = 429, loss = 0.03200, accuracy = 0.97266\n",
      "Epoch = 201, Batch = 429, loss = 0.07884, accuracy = 0.96875\n",
      "Epoch = 202, Batch = 429, loss = 0.03131, accuracy = 0.96875\n",
      "Epoch = 203, Batch = 429, loss = 0.03150, accuracy = 0.96875\n",
      "Epoch = 204, Batch = 429, loss = 0.08520, accuracy = 0.97266\n",
      "Epoch = 205, Batch = 429, loss = 0.06387, accuracy = 0.96875\n",
      "Epoch = 206, Batch = 429, loss = 0.13572, accuracy = 0.96875\n",
      "Epoch = 207, Batch = 429, loss = 0.05424, accuracy = 0.96875\n",
      "Epoch = 208, Batch = 429, loss = 0.01077, accuracy = 0.96875\n",
      "Epoch = 209, Batch = 429, loss = 0.02486, accuracy = 0.96875\n",
      "Epoch = 210, Batch = 429, loss = 0.03525, accuracy = 0.97266\n",
      "Epoch = 211, Batch = 429, loss = 0.04622, accuracy = 0.96875\n",
      "Epoch = 212, Batch = 429, loss = 0.05961, accuracy = 0.96875\n",
      "Epoch = 213, Batch = 429, loss = 0.03860, accuracy = 0.96875\n",
      "Epoch = 214, Batch = 429, loss = 0.05192, accuracy = 0.96875\n",
      "Epoch = 215, Batch = 429, loss = 0.03442, accuracy = 0.96875\n",
      "Epoch = 216, Batch = 429, loss = 0.00970, accuracy = 0.97266\n",
      "Epoch = 217, Batch = 429, loss = 0.03056, accuracy = 0.96875\n",
      "Epoch = 218, Batch = 429, loss = 0.03084, accuracy = 0.97266\n",
      "Epoch = 219, Batch = 429, loss = 0.07500, accuracy = 0.97266\n",
      "Epoch = 220, Batch = 429, loss = 0.00937, accuracy = 0.97266\n",
      "Epoch = 221, Batch = 429, loss = 0.07539, accuracy = 0.97266\n",
      "Epoch = 222, Batch = 429, loss = 0.02860, accuracy = 0.96875\n",
      "Epoch = 223, Batch = 429, loss = 0.01079, accuracy = 0.96875\n",
      "Epoch = 224, Batch = 429, loss = 0.02261, accuracy = 0.97266\n",
      "Epoch = 225, Batch = 429, loss = 0.04035, accuracy = 0.96875\n",
      "Epoch = 226, Batch = 429, loss = 0.02282, accuracy = 0.97266\n",
      "Epoch = 227, Batch = 429, loss = 0.09067, accuracy = 0.96875\n",
      "Epoch = 228, Batch = 429, loss = 0.01795, accuracy = 0.96875\n",
      "Epoch = 229, Batch = 429, loss = 0.01495, accuracy = 0.97266\n",
      "Epoch = 230, Batch = 429, loss = 0.01818, accuracy = 0.96875\n",
      "Epoch = 231, Batch = 429, loss = 0.06029, accuracy = 0.97266\n",
      "Epoch = 232, Batch = 429, loss = 0.06540, accuracy = 0.97266\n",
      "Epoch = 233, Batch = 429, loss = 0.10459, accuracy = 0.97266\n",
      "Epoch = 234, Batch = 429, loss = 0.04795, accuracy = 0.97266\n",
      "Epoch = 235, Batch = 429, loss = 0.08924, accuracy = 0.97266\n",
      "Epoch = 236, Batch = 429, loss = 0.04706, accuracy = 0.97266\n",
      "Epoch = 237, Batch = 429, loss = 0.02999, accuracy = 0.97266\n",
      "Epoch = 238, Batch = 429, loss = 0.03646, accuracy = 0.97266\n",
      "Epoch = 239, Batch = 429, loss = 0.03446, accuracy = 0.97266\n",
      "Epoch = 240, Batch = 429, loss = 0.02325, accuracy = 0.97266\n",
      "Epoch = 241, Batch = 429, loss = 0.04294, accuracy = 0.97266\n",
      "Epoch = 242, Batch = 429, loss = 0.07335, accuracy = 0.97266\n",
      "Epoch = 243, Batch = 429, loss = 0.09832, accuracy = 0.97266\n",
      "Epoch = 244, Batch = 429, loss = 0.04349, accuracy = 0.97266\n",
      "Epoch = 245, Batch = 429, loss = 0.01501, accuracy = 0.96875\n",
      "Epoch = 246, Batch = 429, loss = 0.02372, accuracy = 0.97266\n",
      "Epoch = 247, Batch = 429, loss = 0.02730, accuracy = 0.97266\n",
      "Epoch = 248, Batch = 429, loss = 0.02378, accuracy = 0.97266\n",
      "Epoch = 249, Batch = 429, loss = 0.03890, accuracy = 0.97266\n",
      "Epoch = 250, Batch = 429, loss = 0.01766, accuracy = 0.97266\n",
      "Epoch = 251, Batch = 429, loss = 0.02285, accuracy = 0.97266\n",
      "Epoch = 252, Batch = 429, loss = 0.01938, accuracy = 0.97266\n",
      "Epoch = 253, Batch = 429, loss = 0.06813, accuracy = 0.97266\n",
      "Epoch = 254, Batch = 429, loss = 0.03116, accuracy = 0.97266\n",
      "Epoch = 255, Batch = 429, loss = 0.02787, accuracy = 0.97266\n",
      "Epoch = 256, Batch = 429, loss = 0.02894, accuracy = 0.97266\n",
      "Epoch = 257, Batch = 429, loss = 0.05388, accuracy = 0.97266\n",
      "Epoch = 258, Batch = 429, loss = 0.02565, accuracy = 0.97266\n",
      "Epoch = 259, Batch = 429, loss = 0.05335, accuracy = 0.97266\n",
      "Epoch = 260, Batch = 429, loss = 0.04817, accuracy = 0.96875\n",
      "Epoch = 261, Batch = 429, loss = 0.03700, accuracy = 0.97266\n",
      "Epoch = 262, Batch = 429, loss = 0.07355, accuracy = 0.97266\n",
      "Epoch = 263, Batch = 429, loss = 0.02631, accuracy = 0.97266\n",
      "Epoch = 264, Batch = 429, loss = 0.01939, accuracy = 0.97266\n",
      "Epoch = 265, Batch = 429, loss = 0.10890, accuracy = 0.97266\n",
      "Epoch = 266, Batch = 429, loss = 0.04251, accuracy = 0.97266\n",
      "Epoch = 267, Batch = 429, loss = 0.01599, accuracy = 0.97266\n",
      "Epoch = 268, Batch = 429, loss = 0.08853, accuracy = 0.97266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 269, Batch = 429, loss = 0.18364, accuracy = 0.97266\n",
      "Epoch = 270, Batch = 429, loss = 0.02175, accuracy = 0.97266\n",
      "Epoch = 271, Batch = 429, loss = 0.02138, accuracy = 0.97266\n",
      "Epoch = 272, Batch = 429, loss = 0.06151, accuracy = 0.97266\n",
      "Epoch = 273, Batch = 429, loss = 0.07962, accuracy = 0.97266\n",
      "Epoch = 274, Batch = 429, loss = 0.05511, accuracy = 0.97266\n",
      "Epoch = 275, Batch = 429, loss = 0.08406, accuracy = 0.97266\n",
      "Epoch = 276, Batch = 429, loss = 0.03597, accuracy = 0.97266\n",
      "Epoch = 277, Batch = 429, loss = 0.03026, accuracy = 0.97266\n",
      "Epoch = 278, Batch = 429, loss = 0.02695, accuracy = 0.97266\n",
      "Epoch = 279, Batch = 429, loss = 0.02085, accuracy = 0.97266\n",
      "Epoch = 280, Batch = 429, loss = 0.03424, accuracy = 0.97266\n",
      "Epoch = 281, Batch = 429, loss = 0.01733, accuracy = 0.97266\n",
      "Epoch = 282, Batch = 429, loss = 0.05117, accuracy = 0.97266\n",
      "Epoch = 283, Batch = 429, loss = 0.03238, accuracy = 0.97266\n",
      "Epoch = 284, Batch = 429, loss = 0.05462, accuracy = 0.97266\n",
      "Epoch = 285, Batch = 429, loss = 0.01959, accuracy = 0.97266\n",
      "Epoch = 286, Batch = 429, loss = 0.01636, accuracy = 0.97266\n",
      "Epoch = 287, Batch = 429, loss = 0.05237, accuracy = 0.97266\n",
      "Epoch = 288, Batch = 429, loss = 0.03209, accuracy = 0.97266\n",
      "Epoch = 289, Batch = 429, loss = 0.01841, accuracy = 0.97266\n",
      "Epoch = 290, Batch = 429, loss = 0.01197, accuracy = 0.97266\n",
      "Epoch = 291, Batch = 429, loss = 0.06790, accuracy = 0.97266\n",
      "Epoch = 292, Batch = 429, loss = 0.02884, accuracy = 0.97266\n",
      "Epoch = 293, Batch = 429, loss = 0.04824, accuracy = 0.97266\n",
      "Epoch = 294, Batch = 429, loss = 0.04885, accuracy = 0.97266\n",
      "Epoch = 295, Batch = 429, loss = 0.01161, accuracy = 0.97266\n",
      "Epoch = 296, Batch = 429, loss = 0.05876, accuracy = 0.97266\n",
      "Epoch = 297, Batch = 429, loss = 0.01287, accuracy = 0.97266\n",
      "Epoch = 298, Batch = 429, loss = 0.01951, accuracy = 0.97266\n",
      "Epoch = 299, Batch = 429, loss = 0.01486, accuracy = 0.97266\n",
      "Epoch = 300, Batch = 429, loss = 0.01520, accuracy = 0.97266\n",
      "Epoch = 301, Batch = 429, loss = 0.01817, accuracy = 0.97266\n",
      "Epoch = 302, Batch = 429, loss = 0.01497, accuracy = 0.97266\n",
      "Epoch = 303, Batch = 429, loss = 0.08038, accuracy = 0.97266\n",
      "Epoch = 304, Batch = 429, loss = 0.04491, accuracy = 0.97266\n",
      "Epoch = 305, Batch = 429, loss = 0.03719, accuracy = 0.97266\n",
      "Epoch = 306, Batch = 429, loss = 0.03523, accuracy = 0.97656\n",
      "Epoch = 307, Batch = 429, loss = 0.01442, accuracy = 0.97266\n",
      "Epoch = 308, Batch = 429, loss = 0.04109, accuracy = 0.97266\n",
      "Epoch = 309, Batch = 429, loss = 0.03696, accuracy = 0.97266\n",
      "Epoch = 310, Batch = 429, loss = 0.01383, accuracy = 0.97266\n",
      "Epoch = 311, Batch = 429, loss = 0.03277, accuracy = 0.97266\n",
      "Epoch = 312, Batch = 429, loss = 0.00910, accuracy = 0.97266\n",
      "Epoch = 313, Batch = 429, loss = 0.03898, accuracy = 0.97266\n",
      "Epoch = 314, Batch = 429, loss = 0.04180, accuracy = 0.97266\n",
      "Epoch = 315, Batch = 429, loss = 0.03724, accuracy = 0.97266\n",
      "Epoch = 316, Batch = 429, loss = 0.01488, accuracy = 0.97266\n",
      "Epoch = 317, Batch = 429, loss = 0.01758, accuracy = 0.97266\n",
      "Epoch = 318, Batch = 429, loss = 0.01013, accuracy = 0.97266\n",
      "Epoch = 319, Batch = 429, loss = 0.02512, accuracy = 0.97266\n",
      "Epoch = 320, Batch = 429, loss = 0.05739, accuracy = 0.97266\n",
      "Epoch = 321, Batch = 429, loss = 0.01226, accuracy = 0.97266\n",
      "Epoch = 322, Batch = 429, loss = 0.03467, accuracy = 0.97266\n",
      "Epoch = 323, Batch = 429, loss = 0.02743, accuracy = 0.97656\n",
      "Epoch = 324, Batch = 429, loss = 0.02803, accuracy = 0.97266\n",
      "Epoch = 325, Batch = 429, loss = 0.01112, accuracy = 0.97266\n",
      "Epoch = 326, Batch = 429, loss = 0.04902, accuracy = 0.97266\n",
      "Epoch = 327, Batch = 429, loss = 0.04973, accuracy = 0.97266\n",
      "Epoch = 328, Batch = 429, loss = 0.01002, accuracy = 0.97266\n",
      "Epoch = 329, Batch = 429, loss = 0.03683, accuracy = 0.97266\n",
      "Epoch = 330, Batch = 429, loss = 0.01291, accuracy = 0.97266\n",
      "Epoch = 331, Batch = 429, loss = 0.04358, accuracy = 0.97266\n",
      "Epoch = 332, Batch = 429, loss = 0.04506, accuracy = 0.97656\n",
      "Epoch = 333, Batch = 429, loss = 0.03625, accuracy = 0.97656\n",
      "Epoch = 334, Batch = 429, loss = 0.02474, accuracy = 0.97266\n",
      "Epoch = 335, Batch = 429, loss = 0.04371, accuracy = 0.97266\n",
      "Epoch = 336, Batch = 429, loss = 0.04437, accuracy = 0.97656\n",
      "Epoch = 337, Batch = 429, loss = 0.03704, accuracy = 0.97266\n",
      "Epoch = 338, Batch = 429, loss = 0.01270, accuracy = 0.98047\n",
      "Epoch = 339, Batch = 429, loss = 0.01029, accuracy = 0.97656\n",
      "Epoch = 340, Batch = 429, loss = 0.04043, accuracy = 0.97266\n",
      "Epoch = 341, Batch = 429, loss = 0.01520, accuracy = 0.98047\n",
      "Epoch = 342, Batch = 429, loss = 0.01570, accuracy = 0.97656\n",
      "Epoch = 343, Batch = 429, loss = 0.01954, accuracy = 0.97266\n",
      "Epoch = 344, Batch = 429, loss = 0.03241, accuracy = 0.97266\n",
      "Epoch = 345, Batch = 429, loss = 0.05591, accuracy = 0.97266\n",
      "Epoch = 346, Batch = 429, loss = 0.00674, accuracy = 0.97656\n",
      "Epoch = 347, Batch = 429, loss = 0.02312, accuracy = 0.97266\n",
      "Epoch = 348, Batch = 429, loss = 0.04784, accuracy = 0.97656\n",
      "Epoch = 349, Batch = 429, loss = 0.03604, accuracy = 0.97266\n",
      "Epoch = 350, Batch = 429, loss = 0.03276, accuracy = 0.97656\n",
      "Epoch = 351, Batch = 429, loss = 0.03893, accuracy = 0.97266\n",
      "Epoch = 352, Batch = 429, loss = 0.03903, accuracy = 0.98047\n",
      "Epoch = 353, Batch = 429, loss = 0.01685, accuracy = 0.97656\n",
      "Epoch = 354, Batch = 429, loss = 0.01616, accuracy = 0.97656\n",
      "Epoch = 355, Batch = 429, loss = 0.01986, accuracy = 0.98047\n",
      "Epoch = 356, Batch = 429, loss = 0.04288, accuracy = 0.97656\n",
      "Epoch = 357, Batch = 429, loss = 0.06889, accuracy = 0.97656\n",
      "Epoch = 358, Batch = 429, loss = 0.17541, accuracy = 0.97656\n",
      "Epoch = 359, Batch = 429, loss = 0.06773, accuracy = 0.97656\n",
      "Epoch = 360, Batch = 429, loss = 0.04395, accuracy = 0.98047\n",
      "Epoch = 361, Batch = 429, loss = 0.06014, accuracy = 0.97656\n",
      "Epoch = 362, Batch = 429, loss = 0.03007, accuracy = 0.98047\n",
      "Epoch = 363, Batch = 429, loss = 0.02822, accuracy = 0.97656\n",
      "Epoch = 364, Batch = 429, loss = 0.01067, accuracy = 0.98047\n",
      "Epoch = 365, Batch = 429, loss = 0.00760, accuracy = 0.97656\n",
      "Epoch = 366, Batch = 429, loss = 0.05728, accuracy = 0.98047\n",
      "Epoch = 367, Batch = 429, loss = 0.01638, accuracy = 0.98047\n",
      "Epoch = 368, Batch = 429, loss = 0.03890, accuracy = 0.98047\n",
      "Epoch = 369, Batch = 429, loss = 0.05006, accuracy = 0.98047\n",
      "Epoch = 370, Batch = 429, loss = 0.01393, accuracy = 0.97656\n",
      "Epoch = 371, Batch = 429, loss = 0.02524, accuracy = 0.98047\n",
      "Epoch = 372, Batch = 429, loss = 0.03503, accuracy = 0.98047\n",
      "Epoch = 373, Batch = 429, loss = 0.04568, accuracy = 0.97656\n",
      "Epoch = 374, Batch = 429, loss = 0.00190, accuracy = 0.98047\n",
      "Epoch = 375, Batch = 429, loss = 0.03361, accuracy = 0.98047\n",
      "Epoch = 376, Batch = 429, loss = 0.02139, accuracy = 0.98047\n",
      "Epoch = 377, Batch = 429, loss = 0.06603, accuracy = 0.98047\n",
      "Epoch = 378, Batch = 429, loss = 0.02874, accuracy = 0.98047\n",
      "Epoch = 379, Batch = 429, loss = 0.03437, accuracy = 0.98047\n",
      "Epoch = 380, Batch = 429, loss = 0.02129, accuracy = 0.98047\n",
      "Epoch = 381, Batch = 429, loss = 0.00656, accuracy = 0.98047\n",
      "Epoch = 382, Batch = 429, loss = 0.06766, accuracy = 0.98047\n",
      "Epoch = 383, Batch = 429, loss = 0.01434, accuracy = 0.97656\n",
      "Epoch = 384, Batch = 429, loss = 0.02076, accuracy = 0.97656\n",
      "Epoch = 385, Batch = 429, loss = 0.02561, accuracy = 0.98047\n",
      "Epoch = 386, Batch = 429, loss = 0.04191, accuracy = 0.98047\n",
      "Epoch = 387, Batch = 429, loss = 0.01949, accuracy = 0.97656\n",
      "Epoch = 388, Batch = 429, loss = 0.05193, accuracy = 0.98047\n",
      "Epoch = 389, Batch = 429, loss = 0.02962, accuracy = 0.98047\n",
      "Epoch = 390, Batch = 429, loss = 0.00466, accuracy = 0.98047\n",
      "Epoch = 391, Batch = 429, loss = 0.02491, accuracy = 0.98047\n",
      "Epoch = 392, Batch = 429, loss = 0.04554, accuracy = 0.98047\n",
      "Epoch = 393, Batch = 429, loss = 0.03747, accuracy = 0.98047\n",
      "Epoch = 394, Batch = 429, loss = 0.04879, accuracy = 0.97656\n",
      "Epoch = 395, Batch = 429, loss = 0.01480, accuracy = 0.98047\n",
      "Epoch = 396, Batch = 429, loss = 0.07824, accuracy = 0.97656\n",
      "Epoch = 397, Batch = 429, loss = 0.00362, accuracy = 0.98047\n",
      "Epoch = 398, Batch = 429, loss = 0.03580, accuracy = 0.98047\n",
      "Epoch = 399, Batch = 429, loss = 0.03475, accuracy = 0.98047\n",
      "Epoch = 400, Batch = 429, loss = 0.01277, accuracy = 0.98047\n",
      "Epoch = 401, Batch = 429, loss = 0.04328, accuracy = 0.98047\n",
      "Epoch = 402, Batch = 429, loss = 0.01492, accuracy = 0.97656\n",
      "Epoch = 403, Batch = 429, loss = 0.01141, accuracy = 0.98047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 404, Batch = 429, loss = 0.02292, accuracy = 0.98047\n",
      "Epoch = 405, Batch = 429, loss = 0.03537, accuracy = 0.98047\n",
      "Epoch = 406, Batch = 429, loss = 0.03466, accuracy = 0.98047\n",
      "Epoch = 407, Batch = 429, loss = 0.01668, accuracy = 0.98047\n",
      "Epoch = 408, Batch = 429, loss = 0.05038, accuracy = 0.98047\n",
      "Epoch = 409, Batch = 429, loss = 0.00861, accuracy = 0.98047\n",
      "Epoch = 410, Batch = 429, loss = 0.01992, accuracy = 0.98047\n",
      "Epoch = 411, Batch = 429, loss = 0.04833, accuracy = 0.98047\n",
      "Epoch = 412, Batch = 429, loss = 0.00681, accuracy = 0.98047\n",
      "Epoch = 413, Batch = 429, loss = 0.07548, accuracy = 0.98047\n",
      "Epoch = 414, Batch = 429, loss = 0.01965, accuracy = 0.98047\n",
      "Epoch = 415, Batch = 429, loss = 0.07042, accuracy = 0.98047\n",
      "Epoch = 416, Batch = 429, loss = 0.00470, accuracy = 0.98047\n",
      "Epoch = 417, Batch = 429, loss = 0.05652, accuracy = 0.98047\n",
      "Epoch = 418, Batch = 429, loss = 0.04403, accuracy = 0.98047\n",
      "Epoch = 419, Batch = 429, loss = 0.00298, accuracy = 0.98047\n",
      "Epoch = 420, Batch = 429, loss = 0.02413, accuracy = 0.98047\n",
      "Epoch = 421, Batch = 429, loss = 0.00616, accuracy = 0.98047\n",
      "Epoch = 422, Batch = 429, loss = 0.03202, accuracy = 0.98047\n",
      "Epoch = 423, Batch = 429, loss = 0.02945, accuracy = 0.98047\n",
      "Epoch = 424, Batch = 429, loss = 0.00780, accuracy = 0.98047\n",
      "Epoch = 425, Batch = 429, loss = 0.01993, accuracy = 0.98047\n",
      "Epoch = 426, Batch = 429, loss = 0.06802, accuracy = 0.97656\n",
      "Epoch = 427, Batch = 429, loss = 0.01846, accuracy = 0.98047\n",
      "Epoch = 428, Batch = 429, loss = 0.07266, accuracy = 0.98047\n",
      "Epoch = 429, Batch = 429, loss = 0.01354, accuracy = 0.98047\n",
      "Epoch = 430, Batch = 429, loss = 0.00422, accuracy = 0.98047\n",
      "Epoch = 431, Batch = 429, loss = 0.01112, accuracy = 0.98047\n",
      "Epoch = 432, Batch = 429, loss = 0.02151, accuracy = 0.98047\n",
      "Epoch = 433, Batch = 429, loss = 0.02130, accuracy = 0.98047\n",
      "Epoch = 434, Batch = 429, loss = 0.06596, accuracy = 0.98047\n",
      "Epoch = 435, Batch = 429, loss = 0.01421, accuracy = 0.98047\n",
      "Epoch = 436, Batch = 429, loss = 0.00628, accuracy = 0.98047\n",
      "Epoch = 437, Batch = 429, loss = 0.05857, accuracy = 0.98047\n",
      "Epoch = 438, Batch = 429, loss = 0.00677, accuracy = 0.98047\n",
      "Epoch = 439, Batch = 429, loss = 0.02277, accuracy = 0.98047\n",
      "Epoch = 440, Batch = 429, loss = 0.02205, accuracy = 0.98047\n",
      "Epoch = 441, Batch = 429, loss = 0.04683, accuracy = 0.98047\n",
      "Epoch = 442, Batch = 429, loss = 0.00622, accuracy = 0.98047\n",
      "Epoch = 443, Batch = 429, loss = 0.00515, accuracy = 0.98047\n",
      "Epoch = 444, Batch = 429, loss = 0.01029, accuracy = 0.98047\n",
      "Epoch = 445, Batch = 429, loss = 0.01727, accuracy = 0.97656\n",
      "Epoch = 446, Batch = 429, loss = 0.02096, accuracy = 0.98047\n",
      "Epoch = 447, Batch = 429, loss = 0.00717, accuracy = 0.98047\n",
      "Epoch = 448, Batch = 429, loss = 0.01128, accuracy = 0.98047\n",
      "Epoch = 449, Batch = 429, loss = 0.03681, accuracy = 0.98047\n",
      "Epoch = 450, Batch = 429, loss = 0.06467, accuracy = 0.98047\n",
      "Epoch = 451, Batch = 429, loss = 0.01036, accuracy = 0.98047\n",
      "Epoch = 452, Batch = 429, loss = 0.01253, accuracy = 0.98047\n",
      "Epoch = 453, Batch = 429, loss = 0.00657, accuracy = 0.98047\n",
      "Epoch = 454, Batch = 429, loss = 0.05547, accuracy = 0.98047\n",
      "Epoch = 455, Batch = 429, loss = 0.06438, accuracy = 0.98047\n",
      "Epoch = 456, Batch = 429, loss = 0.01252, accuracy = 0.98047\n",
      "Epoch = 457, Batch = 429, loss = 0.03923, accuracy = 0.98047\n",
      "Epoch = 458, Batch = 429, loss = 0.00368, accuracy = 0.98047\n",
      "Epoch = 459, Batch = 429, loss = 0.01016, accuracy = 0.98047\n",
      "Epoch = 460, Batch = 429, loss = 0.01154, accuracy = 0.98047\n",
      "Epoch = 461, Batch = 429, loss = 0.02209, accuracy = 0.98047\n",
      "Epoch = 462, Batch = 429, loss = 0.02805, accuracy = 0.98047\n",
      "Epoch = 463, Batch = 429, loss = 0.01549, accuracy = 0.98047\n",
      "Epoch = 464, Batch = 429, loss = 0.02372, accuracy = 0.98047\n",
      "Epoch = 465, Batch = 429, loss = 0.04237, accuracy = 0.98047\n",
      "Epoch = 466, Batch = 429, loss = 0.01397, accuracy = 0.98047\n",
      "Epoch = 467, Batch = 429, loss = 0.01808, accuracy = 0.98047\n",
      "Epoch = 468, Batch = 429, loss = 0.03396, accuracy = 0.98047\n",
      "Epoch = 469, Batch = 429, loss = 0.05925, accuracy = 0.98047\n",
      "Epoch = 470, Batch = 429, loss = 0.01371, accuracy = 0.98047\n",
      "Epoch = 471, Batch = 429, loss = 0.01160, accuracy = 0.98047\n",
      "Epoch = 472, Batch = 429, loss = 0.00770, accuracy = 0.98047\n",
      "Epoch = 473, Batch = 429, loss = 0.01767, accuracy = 0.98047\n",
      "Epoch = 474, Batch = 429, loss = 0.03084, accuracy = 0.98047\n",
      "Epoch = 475, Batch = 429, loss = 0.01835, accuracy = 0.98047\n",
      "Epoch = 476, Batch = 429, loss = 0.00592, accuracy = 0.98047\n",
      "Epoch = 477, Batch = 429, loss = 0.05870, accuracy = 0.98047\n",
      "Epoch = 478, Batch = 429, loss = 0.01259, accuracy = 0.98047\n",
      "Epoch = 479, Batch = 429, loss = 0.01425, accuracy = 0.98047\n",
      "Epoch = 480, Batch = 429, loss = 0.02443, accuracy = 0.98047\n",
      "Epoch = 481, Batch = 429, loss = 0.00348, accuracy = 0.98047\n",
      "Epoch = 482, Batch = 429, loss = 0.03197, accuracy = 0.98047\n",
      "Epoch = 483, Batch = 429, loss = 0.00625, accuracy = 0.98047\n",
      "Epoch = 484, Batch = 429, loss = 0.04548, accuracy = 0.98047\n",
      "Epoch = 485, Batch = 429, loss = 0.07158, accuracy = 0.98047\n",
      "Epoch = 486, Batch = 429, loss = 0.08029, accuracy = 0.98047\n",
      "Epoch = 487, Batch = 429, loss = 0.01151, accuracy = 0.98047\n",
      "Epoch = 488, Batch = 429, loss = 0.01179, accuracy = 0.98047\n",
      "Epoch = 489, Batch = 429, loss = 0.00573, accuracy = 0.98047\n",
      "Epoch = 490, Batch = 429, loss = 0.03773, accuracy = 0.98047\n",
      "Epoch = 491, Batch = 429, loss = 0.02196, accuracy = 0.98047\n",
      "Epoch = 492, Batch = 429, loss = 0.00156, accuracy = 0.98047\n",
      "Epoch = 493, Batch = 429, loss = 0.00442, accuracy = 0.98047\n",
      "Epoch = 494, Batch = 429, loss = 0.01490, accuracy = 0.98047\n",
      "Epoch = 495, Batch = 429, loss = 0.08273, accuracy = 0.98047\n",
      "Epoch = 496, Batch = 429, loss = 0.00839, accuracy = 0.98047\n",
      "Epoch = 497, Batch = 429, loss = 0.01543, accuracy = 0.98047\n",
      "Epoch = 498, Batch = 429, loss = 0.01156, accuracy = 0.98047\n",
      "Epoch = 499, Batch = 429, loss = 0.01295, accuracy = 0.98047\n",
      "Epoch = 500, Batch = 429, loss = 0.00353, accuracy = 0.98047\n",
      "Epoch = 501, Batch = 429, loss = 0.00527, accuracy = 0.98047\n",
      "Epoch = 502, Batch = 429, loss = 0.01908, accuracy = 0.98047\n",
      "Epoch = 503, Batch = 429, loss = 0.03690, accuracy = 0.98047\n",
      "Epoch = 504, Batch = 429, loss = 0.05239, accuracy = 0.98047\n",
      "Epoch = 505, Batch = 429, loss = 0.02222, accuracy = 0.98047\n",
      "Epoch = 506, Batch = 429, loss = 0.01761, accuracy = 0.98047\n",
      "Epoch = 507, Batch = 429, loss = 0.02002, accuracy = 0.98047\n",
      "Epoch = 508, Batch = 429, loss = 0.01221, accuracy = 0.98047\n",
      "Epoch = 509, Batch = 429, loss = 0.04090, accuracy = 0.98047\n",
      "Epoch = 510, Batch = 429, loss = 0.01720, accuracy = 0.98047\n",
      "Epoch = 511, Batch = 429, loss = 0.00928, accuracy = 0.98047\n",
      "Epoch = 512, Batch = 429, loss = 0.01011, accuracy = 0.98047\n",
      "Epoch = 513, Batch = 429, loss = 0.03043, accuracy = 0.98047\n",
      "Epoch = 514, Batch = 429, loss = 0.02102, accuracy = 0.98047\n",
      "Epoch = 515, Batch = 429, loss = 0.01855, accuracy = 0.98047\n",
      "Epoch = 516, Batch = 429, loss = 0.00747, accuracy = 0.98047\n",
      "Epoch = 517, Batch = 429, loss = 0.00581, accuracy = 0.98047\n",
      "Epoch = 518, Batch = 429, loss = 0.03905, accuracy = 0.98047\n",
      "Epoch = 519, Batch = 429, loss = 0.00272, accuracy = 0.98047\n",
      "Epoch = 520, Batch = 429, loss = 0.01300, accuracy = 0.98047\n",
      "Epoch = 521, Batch = 429, loss = 0.02096, accuracy = 0.98047\n",
      "Epoch = 522, Batch = 429, loss = 0.03241, accuracy = 0.98047\n",
      "Epoch = 523, Batch = 429, loss = 0.01649, accuracy = 0.98047\n",
      "Epoch = 524, Batch = 429, loss = 0.00655, accuracy = 0.98047\n",
      "Epoch = 525, Batch = 429, loss = 0.01793, accuracy = 0.98047\n",
      "Epoch = 526, Batch = 429, loss = 0.01363, accuracy = 0.98047\n",
      "Epoch = 527, Batch = 429, loss = 0.00277, accuracy = 0.98047\n",
      "Epoch = 528, Batch = 429, loss = 0.01205, accuracy = 0.98047\n",
      "Epoch = 529, Batch = 429, loss = 0.01009, accuracy = 0.98047\n",
      "Epoch = 530, Batch = 429, loss = 0.02288, accuracy = 0.98047\n",
      "Epoch = 531, Batch = 429, loss = 0.02842, accuracy = 0.98047\n",
      "Epoch = 532, Batch = 429, loss = 0.04201, accuracy = 0.98047\n",
      "Epoch = 533, Batch = 429, loss = 0.02576, accuracy = 0.98047\n",
      "Epoch = 534, Batch = 429, loss = 0.01522, accuracy = 0.98047\n",
      "Epoch = 535, Batch = 429, loss = 0.00853, accuracy = 0.98047\n",
      "Epoch = 536, Batch = 429, loss = 0.00507, accuracy = 0.98047\n",
      "Epoch = 537, Batch = 429, loss = 0.00768, accuracy = 0.98047\n",
      "Epoch = 538, Batch = 429, loss = 0.01336, accuracy = 0.98047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 539, Batch = 429, loss = 0.00185, accuracy = 0.98047\n",
      "Epoch = 540, Batch = 429, loss = 0.01847, accuracy = 0.98047\n",
      "Epoch = 541, Batch = 429, loss = 0.00833, accuracy = 0.98047\n",
      "Epoch = 542, Batch = 429, loss = 0.00746, accuracy = 0.98047\n",
      "Epoch = 543, Batch = 429, loss = 0.02045, accuracy = 0.98047\n",
      "Epoch = 544, Batch = 429, loss = 0.00541, accuracy = 0.98047\n",
      "Epoch = 545, Batch = 429, loss = 0.04548, accuracy = 0.98047\n",
      "Epoch = 546, Batch = 429, loss = 0.01248, accuracy = 0.98047\n",
      "Epoch = 547, Batch = 429, loss = 0.01269, accuracy = 0.98047\n",
      "Epoch = 548, Batch = 429, loss = 0.01263, accuracy = 0.98047\n",
      "Epoch = 549, Batch = 429, loss = 0.00685, accuracy = 0.98047\n",
      "Epoch = 550, Batch = 429, loss = 0.02823, accuracy = 0.98047\n",
      "Epoch = 551, Batch = 429, loss = 0.01487, accuracy = 0.98047\n",
      "Epoch = 552, Batch = 429, loss = 0.02470, accuracy = 0.98047\n",
      "Epoch = 553, Batch = 429, loss = 0.01142, accuracy = 0.98047\n",
      "Epoch = 554, Batch = 429, loss = 0.00333, accuracy = 0.98047\n",
      "Epoch = 555, Batch = 429, loss = 0.02174, accuracy = 0.98047\n",
      "Epoch = 556, Batch = 429, loss = 0.01533, accuracy = 0.98047\n",
      "Epoch = 557, Batch = 429, loss = 0.01086, accuracy = 0.98047\n",
      "Epoch = 558, Batch = 429, loss = 0.00443, accuracy = 0.98047\n",
      "Epoch = 559, Batch = 429, loss = 0.00948, accuracy = 0.98047\n",
      "Epoch = 560, Batch = 429, loss = 0.03602, accuracy = 0.98047\n",
      "Epoch = 561, Batch = 429, loss = 0.01606, accuracy = 0.98047\n",
      "Epoch = 562, Batch = 429, loss = 0.05608, accuracy = 0.98047\n",
      "Epoch = 563, Batch = 429, loss = 0.01700, accuracy = 0.98047\n",
      "Epoch = 564, Batch = 429, loss = 0.00824, accuracy = 0.98047\n",
      "Epoch = 565, Batch = 429, loss = 0.00593, accuracy = 0.98047\n",
      "Epoch = 566, Batch = 429, loss = 0.00630, accuracy = 0.98047\n",
      "Epoch = 567, Batch = 429, loss = 0.00378, accuracy = 0.98047\n",
      "Epoch = 568, Batch = 429, loss = 0.01127, accuracy = 0.98047\n",
      "Epoch = 569, Batch = 429, loss = 0.00555, accuracy = 0.98047\n",
      "Epoch = 570, Batch = 429, loss = 0.00690, accuracy = 0.98047\n",
      "Epoch = 571, Batch = 429, loss = 0.01538, accuracy = 0.98047\n",
      "Epoch = 572, Batch = 429, loss = 0.00369, accuracy = 0.98047\n",
      "Epoch = 573, Batch = 429, loss = 0.06014, accuracy = 0.98047\n",
      "Epoch = 574, Batch = 429, loss = 0.01742, accuracy = 0.98047\n",
      "Epoch = 575, Batch = 429, loss = 0.00542, accuracy = 0.98047\n",
      "Epoch = 576, Batch = 429, loss = 0.02574, accuracy = 0.98047\n",
      "Epoch = 577, Batch = 429, loss = 0.02778, accuracy = 0.98047\n",
      "Epoch = 578, Batch = 429, loss = 0.00726, accuracy = 0.98047\n",
      "Epoch = 579, Batch = 429, loss = 0.02891, accuracy = 0.98047\n",
      "Epoch = 580, Batch = 429, loss = 0.00945, accuracy = 0.98047\n",
      "Epoch = 581, Batch = 429, loss = 0.06397, accuracy = 0.98047\n",
      "Epoch = 582, Batch = 429, loss = 0.03730, accuracy = 0.98047\n",
      "Epoch = 583, Batch = 429, loss = 0.02371, accuracy = 0.98047\n",
      "Epoch = 584, Batch = 429, loss = 0.00420, accuracy = 0.98047\n",
      "Epoch = 585, Batch = 429, loss = 0.02874, accuracy = 0.98047\n",
      "Epoch = 586, Batch = 429, loss = 0.01609, accuracy = 0.98047\n",
      "Epoch = 587, Batch = 429, loss = 0.01683, accuracy = 0.98047\n",
      "Epoch = 588, Batch = 429, loss = 0.00362, accuracy = 0.98047\n",
      "Epoch = 589, Batch = 429, loss = 0.00238, accuracy = 0.98047\n",
      "Epoch = 590, Batch = 429, loss = 0.01687, accuracy = 0.98047\n",
      "Epoch = 591, Batch = 429, loss = 0.07899, accuracy = 0.98047\n",
      "Epoch = 592, Batch = 429, loss = 0.00288, accuracy = 0.98047\n",
      "Epoch = 593, Batch = 429, loss = 0.00584, accuracy = 0.98047\n",
      "Epoch = 594, Batch = 429, loss = 0.00375, accuracy = 0.98047\n",
      "Epoch = 595, Batch = 429, loss = 0.00933, accuracy = 0.98047\n",
      "Epoch = 596, Batch = 429, loss = 0.01793, accuracy = 0.98047\n",
      "Epoch = 597, Batch = 429, loss = 0.00696, accuracy = 0.98047\n",
      "Epoch = 598, Batch = 429, loss = 0.00557, accuracy = 0.98047\n",
      "Epoch = 599, Batch = 429, loss = 0.01066, accuracy = 0.98047\n",
      "Epoch = 600, Batch = 429, loss = 0.00970, accuracy = 0.98047\n",
      "Epoch = 601, Batch = 429, loss = 0.01457, accuracy = 0.98047\n",
      "Epoch = 602, Batch = 429, loss = 0.00629, accuracy = 0.98047\n",
      "Epoch = 603, Batch = 429, loss = 0.01108, accuracy = 0.98047\n",
      "Epoch = 604, Batch = 429, loss = 0.01340, accuracy = 0.98047\n",
      "Epoch = 605, Batch = 429, loss = 0.00922, accuracy = 0.98047\n",
      "Epoch = 606, Batch = 429, loss = 0.02717, accuracy = 0.98047\n",
      "Epoch = 607, Batch = 429, loss = 0.01216, accuracy = 0.98047\n",
      "Epoch = 608, Batch = 429, loss = 0.00563, accuracy = 0.98047\n",
      "Epoch = 609, Batch = 429, loss = 0.05092, accuracy = 0.98047\n",
      "Epoch = 610, Batch = 429, loss = 0.01047, accuracy = 0.98047\n",
      "Epoch = 611, Batch = 429, loss = 0.01131, accuracy = 0.98047\n",
      "Epoch = 612, Batch = 429, loss = 0.00958, accuracy = 0.98047\n",
      "Epoch = 613, Batch = 429, loss = 0.01075, accuracy = 0.98047\n",
      "Epoch = 614, Batch = 429, loss = 0.03081, accuracy = 0.98047\n",
      "Epoch = 615, Batch = 429, loss = 0.01335, accuracy = 0.98047\n",
      "Epoch = 616, Batch = 429, loss = 0.00063, accuracy = 0.98047\n",
      "Epoch = 617, Batch = 429, loss = 0.01185, accuracy = 0.98047\n",
      "Epoch = 618, Batch = 429, loss = 0.01424, accuracy = 0.98047\n",
      "Epoch = 619, Batch = 429, loss = 0.00358, accuracy = 0.98047\n",
      "Epoch = 620, Batch = 429, loss = 0.02740, accuracy = 0.98047\n",
      "Epoch = 621, Batch = 429, loss = 0.01296, accuracy = 0.98047\n",
      "Epoch = 622, Batch = 429, loss = 0.00245, accuracy = 0.98047\n",
      "Epoch = 623, Batch = 429, loss = 0.01366, accuracy = 0.98047\n",
      "Epoch = 624, Batch = 429, loss = 0.01809, accuracy = 0.98047\n",
      "Epoch = 625, Batch = 429, loss = 0.00341, accuracy = 0.98047\n",
      "Epoch = 626, Batch = 429, loss = 0.01967, accuracy = 0.98047\n",
      "Epoch = 627, Batch = 429, loss = 0.00687, accuracy = 0.98047\n",
      "Epoch = 628, Batch = 429, loss = 0.01194, accuracy = 0.98047\n",
      "Epoch = 629, Batch = 429, loss = 0.01416, accuracy = 0.98047\n",
      "Epoch = 630, Batch = 429, loss = 0.01024, accuracy = 0.98047\n",
      "Epoch = 631, Batch = 429, loss = 0.00637, accuracy = 0.98047\n",
      "Epoch = 632, Batch = 429, loss = 0.01980, accuracy = 0.98047\n",
      "Epoch = 633, Batch = 429, loss = 0.00496, accuracy = 0.98047\n",
      "Epoch = 634, Batch = 429, loss = 0.00437, accuracy = 0.98047\n",
      "Epoch = 635, Batch = 429, loss = 0.00185, accuracy = 0.98047\n",
      "Epoch = 636, Batch = 429, loss = 0.00675, accuracy = 0.98047\n",
      "Epoch = 637, Batch = 429, loss = 0.02622, accuracy = 0.98047\n",
      "Epoch = 638, Batch = 429, loss = 0.00558, accuracy = 0.98047\n",
      "Epoch = 639, Batch = 429, loss = 0.00464, accuracy = 0.98047\n",
      "Epoch = 640, Batch = 429, loss = 0.01306, accuracy = 0.98047\n",
      "Epoch = 641, Batch = 429, loss = 0.02692, accuracy = 0.98047\n",
      "Epoch = 642, Batch = 429, loss = 0.01405, accuracy = 0.98047\n",
      "Epoch = 643, Batch = 429, loss = 0.01574, accuracy = 0.98047\n",
      "Epoch = 644, Batch = 429, loss = 0.00803, accuracy = 0.98047\n",
      "Epoch = 645, Batch = 429, loss = 0.00246, accuracy = 0.98047\n",
      "Epoch = 646, Batch = 429, loss = 0.02076, accuracy = 0.98047\n",
      "Epoch = 647, Batch = 429, loss = 0.02644, accuracy = 0.98047\n",
      "Epoch = 648, Batch = 429, loss = 0.00078, accuracy = 0.98047\n",
      "Epoch = 649, Batch = 429, loss = 0.01064, accuracy = 0.98047\n",
      "Epoch = 650, Batch = 429, loss = 0.00519, accuracy = 0.98047\n",
      "Epoch = 651, Batch = 429, loss = 0.02553, accuracy = 0.98047\n",
      "Epoch = 652, Batch = 429, loss = 0.01547, accuracy = 0.98047\n",
      "Epoch = 653, Batch = 429, loss = 0.00268, accuracy = 0.98047\n",
      "Epoch = 654, Batch = 429, loss = 0.03304, accuracy = 0.98047\n",
      "Epoch = 655, Batch = 429, loss = 0.01033, accuracy = 0.98047\n",
      "Epoch = 656, Batch = 429, loss = 0.00518, accuracy = 0.98047\n",
      "Epoch = 657, Batch = 429, loss = 0.00071, accuracy = 0.98047\n",
      "Epoch = 658, Batch = 429, loss = 0.01087, accuracy = 0.98047\n",
      "Epoch = 659, Batch = 429, loss = 0.01762, accuracy = 0.98047\n",
      "Epoch = 660, Batch = 429, loss = 0.00720, accuracy = 0.98047\n",
      "Epoch = 661, Batch = 429, loss = 0.01885, accuracy = 0.98047\n",
      "Epoch = 662, Batch = 429, loss = 0.00681, accuracy = 0.98047\n",
      "Epoch = 663, Batch = 429, loss = 0.00417, accuracy = 0.98047\n",
      "Epoch = 664, Batch = 429, loss = 0.03315, accuracy = 0.98047\n",
      "Epoch = 665, Batch = 429, loss = 0.02673, accuracy = 0.98047\n",
      "Epoch = 666, Batch = 429, loss = 0.03655, accuracy = 0.98047\n",
      "Epoch = 667, Batch = 429, loss = 0.05665, accuracy = 0.98047\n",
      "Epoch = 668, Batch = 429, loss = 0.00565, accuracy = 0.98047\n",
      "Epoch = 669, Batch = 429, loss = 0.00789, accuracy = 0.98047\n",
      "Epoch = 670, Batch = 429, loss = 0.00961, accuracy = 0.98047\n",
      "Epoch = 671, Batch = 429, loss = 0.00709, accuracy = 0.98047\n",
      "Epoch = 672, Batch = 429, loss = 0.00374, accuracy = 0.98047\n",
      "Epoch = 673, Batch = 429, loss = 0.00094, accuracy = 0.98047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 674, Batch = 429, loss = 0.00227, accuracy = 0.98047\n",
      "Epoch = 675, Batch = 429, loss = 0.00431, accuracy = 0.98047\n",
      "Epoch = 676, Batch = 429, loss = 0.00450, accuracy = 0.98047\n",
      "Epoch = 677, Batch = 429, loss = 0.00108, accuracy = 0.98047\n",
      "Epoch = 678, Batch = 429, loss = 0.01865, accuracy = 0.98047\n",
      "Epoch = 679, Batch = 429, loss = 0.03083, accuracy = 0.98047\n",
      "Epoch = 680, Batch = 429, loss = 0.00573, accuracy = 0.98047\n",
      "Epoch = 681, Batch = 429, loss = 0.00268, accuracy = 0.98047\n",
      "Epoch = 682, Batch = 429, loss = 0.03635, accuracy = 0.98047\n",
      "Epoch = 683, Batch = 429, loss = 0.00343, accuracy = 0.98047\n",
      "Epoch = 684, Batch = 429, loss = 0.01401, accuracy = 0.98047\n",
      "Epoch = 685, Batch = 429, loss = 0.00792, accuracy = 0.98047\n",
      "Epoch = 686, Batch = 429, loss = 0.00246, accuracy = 0.98047\n",
      "Epoch = 687, Batch = 429, loss = 0.00126, accuracy = 0.98047\n",
      "Epoch = 688, Batch = 429, loss = 0.00828, accuracy = 0.98047\n",
      "Epoch = 689, Batch = 429, loss = 0.00628, accuracy = 0.98047\n",
      "Epoch = 690, Batch = 429, loss = 0.00315, accuracy = 0.98047\n",
      "Epoch = 691, Batch = 429, loss = 0.00416, accuracy = 0.98047\n",
      "Epoch = 692, Batch = 429, loss = 0.00768, accuracy = 0.98047\n",
      "Epoch = 693, Batch = 429, loss = 0.00719, accuracy = 0.98047\n",
      "Epoch = 694, Batch = 429, loss = 0.03157, accuracy = 0.98047\n",
      "Epoch = 695, Batch = 429, loss = 0.00270, accuracy = 0.98047\n",
      "Epoch = 696, Batch = 429, loss = 0.04588, accuracy = 0.98047\n",
      "Epoch = 697, Batch = 429, loss = 0.00321, accuracy = 0.98047\n",
      "Epoch = 698, Batch = 429, loss = 0.00153, accuracy = 0.98047\n",
      "Epoch = 699, Batch = 429, loss = 0.00321, accuracy = 0.98047\n",
      "Epoch = 700, Batch = 429, loss = 0.00170, accuracy = 0.98047\n",
      "Epoch = 701, Batch = 429, loss = 0.00350, accuracy = 0.98047\n",
      "Epoch = 702, Batch = 429, loss = 0.02872, accuracy = 0.98047\n",
      "Epoch = 703, Batch = 429, loss = 0.00654, accuracy = 0.98047\n",
      "Epoch = 704, Batch = 429, loss = 0.01242, accuracy = 0.98047\n",
      "Epoch = 705, Batch = 429, loss = 0.00732, accuracy = 0.98047\n",
      "Epoch = 706, Batch = 429, loss = 0.02113, accuracy = 0.98047\n",
      "Epoch = 707, Batch = 429, loss = 0.00601, accuracy = 0.98047\n",
      "Epoch = 708, Batch = 429, loss = 0.00428, accuracy = 0.98047\n",
      "Epoch = 709, Batch = 429, loss = 0.01247, accuracy = 0.98047\n",
      "Epoch = 710, Batch = 429, loss = 0.02434, accuracy = 0.98047\n",
      "Epoch = 711, Batch = 429, loss = 0.00741, accuracy = 0.98047\n",
      "Epoch = 712, Batch = 429, loss = 0.01047, accuracy = 0.98047\n",
      "Epoch = 713, Batch = 429, loss = 0.00209, accuracy = 0.98047\n",
      "Epoch = 714, Batch = 429, loss = 0.00657, accuracy = 0.98047\n",
      "Epoch = 715, Batch = 429, loss = 0.02178, accuracy = 0.98047\n",
      "Epoch = 716, Batch = 429, loss = 0.00183, accuracy = 0.98047\n",
      "Epoch = 717, Batch = 429, loss = 0.01993, accuracy = 0.98047\n",
      "Epoch = 718, Batch = 429, loss = 0.00478, accuracy = 0.98047\n",
      "Epoch = 719, Batch = 429, loss = 0.01683, accuracy = 0.98047\n",
      "Epoch = 720, Batch = 429, loss = 0.00697, accuracy = 0.98047\n",
      "Epoch = 721, Batch = 429, loss = 0.12039, accuracy = 0.98047\n",
      "Epoch = 722, Batch = 429, loss = 0.02377, accuracy = 0.98047\n",
      "Epoch = 723, Batch = 429, loss = 0.00889, accuracy = 0.98047\n",
      "Epoch = 724, Batch = 429, loss = 0.05702, accuracy = 0.98047\n",
      "Epoch = 725, Batch = 429, loss = 0.01793, accuracy = 0.98047\n",
      "Epoch = 726, Batch = 429, loss = 0.00542, accuracy = 0.98047\n",
      "Epoch = 727, Batch = 429, loss = 0.03835, accuracy = 0.98047\n",
      "Epoch = 728, Batch = 429, loss = 0.00266, accuracy = 0.98047\n",
      "Epoch = 729, Batch = 429, loss = 0.03798, accuracy = 0.98047\n",
      "Epoch = 730, Batch = 429, loss = 0.00058, accuracy = 0.98047\n",
      "Epoch = 731, Batch = 429, loss = 0.00260, accuracy = 0.98047\n",
      "Epoch = 732, Batch = 429, loss = 0.00727, accuracy = 0.98047\n",
      "Epoch = 733, Batch = 429, loss = 0.00490, accuracy = 0.98047\n",
      "Epoch = 734, Batch = 429, loss = 0.00376, accuracy = 0.98047\n",
      "Epoch = 735, Batch = 429, loss = 0.02626, accuracy = 0.98047\n",
      "Epoch = 736, Batch = 429, loss = 0.00846, accuracy = 0.98047\n",
      "Epoch = 737, Batch = 429, loss = 0.00419, accuracy = 0.98047\n",
      "Epoch = 738, Batch = 429, loss = 0.01004, accuracy = 0.98047\n",
      "Epoch = 739, Batch = 429, loss = 0.00694, accuracy = 0.98047\n",
      "Epoch = 740, Batch = 429, loss = 0.00692, accuracy = 0.98047\n",
      "Epoch = 741, Batch = 429, loss = 0.00478, accuracy = 0.98047\n",
      "Epoch = 742, Batch = 429, loss = 0.00180, accuracy = 0.98047\n",
      "Epoch = 743, Batch = 429, loss = 0.00520, accuracy = 0.98047\n",
      "Epoch = 744, Batch = 429, loss = 0.01024, accuracy = 0.98047\n",
      "Epoch = 745, Batch = 429, loss = 0.00493, accuracy = 0.98047\n",
      "Epoch = 746, Batch = 429, loss = 0.00201, accuracy = 0.98047\n",
      "Epoch = 747, Batch = 429, loss = 0.04886, accuracy = 0.98047\n",
      "Epoch = 748, Batch = 429, loss = 0.00109, accuracy = 0.98047\n",
      "Epoch = 749, Batch = 429, loss = 0.01439, accuracy = 0.98047\n",
      "Epoch = 750, Batch = 429, loss = 0.00219, accuracy = 0.98047\n",
      "Epoch = 751, Batch = 429, loss = 0.00595, accuracy = 0.98047\n",
      "Epoch = 752, Batch = 429, loss = 0.00257, accuracy = 0.98047\n",
      "Epoch = 753, Batch = 429, loss = 0.02617, accuracy = 0.98047\n",
      "Epoch = 754, Batch = 429, loss = 0.04037, accuracy = 0.98047\n",
      "Epoch = 755, Batch = 429, loss = 0.00275, accuracy = 0.98047\n",
      "Epoch = 756, Batch = 429, loss = 0.00240, accuracy = 0.98047\n",
      "Epoch = 757, Batch = 429, loss = 0.00624, accuracy = 0.98047\n",
      "Epoch = 758, Batch = 429, loss = 0.03220, accuracy = 0.98047\n",
      "Epoch = 759, Batch = 429, loss = 0.00312, accuracy = 0.98047\n",
      "Epoch = 760, Batch = 429, loss = 0.00691, accuracy = 0.98047\n",
      "Epoch = 761, Batch = 429, loss = 0.00957, accuracy = 0.98047\n",
      "Epoch = 762, Batch = 429, loss = 0.00585, accuracy = 0.98047\n",
      "Epoch = 763, Batch = 429, loss = 0.01775, accuracy = 0.98047\n",
      "Epoch = 764, Batch = 429, loss = 0.00514, accuracy = 0.98047\n",
      "Epoch = 765, Batch = 429, loss = 0.00370, accuracy = 0.98047\n",
      "Epoch = 766, Batch = 429, loss = 0.01264, accuracy = 0.98047\n",
      "Epoch = 767, Batch = 429, loss = 0.00553, accuracy = 0.98047\n",
      "Epoch = 768, Batch = 429, loss = 0.00508, accuracy = 0.98047\n",
      "Epoch = 769, Batch = 429, loss = 0.00359, accuracy = 0.98047\n",
      "Epoch = 770, Batch = 429, loss = 0.00710, accuracy = 0.98047\n",
      "Epoch = 771, Batch = 429, loss = 0.00876, accuracy = 0.98047\n",
      "Epoch = 772, Batch = 429, loss = 0.00813, accuracy = 0.98047\n",
      "Epoch = 773, Batch = 429, loss = 0.00149, accuracy = 0.98047\n",
      "Epoch = 774, Batch = 429, loss = 0.00523, accuracy = 0.98047\n",
      "Epoch = 775, Batch = 429, loss = 0.00835, accuracy = 0.98047\n",
      "Epoch = 776, Batch = 429, loss = 0.00198, accuracy = 0.98047\n",
      "Epoch = 777, Batch = 429, loss = 0.00148, accuracy = 0.98047\n",
      "Epoch = 778, Batch = 429, loss = 0.00099, accuracy = 0.98047\n",
      "Epoch = 779, Batch = 429, loss = 0.00265, accuracy = 0.98047\n",
      "Epoch = 780, Batch = 429, loss = 0.00368, accuracy = 0.98047\n",
      "Epoch = 781, Batch = 429, loss = 0.00137, accuracy = 0.98047\n",
      "Epoch = 782, Batch = 429, loss = 0.00328, accuracy = 0.98047\n",
      "Epoch = 783, Batch = 429, loss = 0.01211, accuracy = 0.98047\n",
      "Epoch = 784, Batch = 429, loss = 0.00174, accuracy = 0.98047\n",
      "Epoch = 785, Batch = 429, loss = 0.00474, accuracy = 0.98047\n",
      "Epoch = 786, Batch = 429, loss = 0.00343, accuracy = 0.98047\n",
      "Epoch = 787, Batch = 429, loss = 0.01035, accuracy = 0.98047\n",
      "Epoch = 788, Batch = 429, loss = 0.00292, accuracy = 0.98047\n",
      "Epoch = 789, Batch = 429, loss = 0.04473, accuracy = 0.98047\n",
      "Epoch = 790, Batch = 429, loss = 0.00421, accuracy = 0.98047\n",
      "Epoch = 791, Batch = 429, loss = 0.02351, accuracy = 0.98047\n",
      "Epoch = 792, Batch = 429, loss = 0.00433, accuracy = 0.98047\n",
      "Epoch = 793, Batch = 429, loss = 0.00279, accuracy = 0.98047\n",
      "Epoch = 794, Batch = 429, loss = 0.05034, accuracy = 0.98047\n",
      "Epoch = 795, Batch = 429, loss = 0.00636, accuracy = 0.98047\n",
      "Epoch = 796, Batch = 429, loss = 0.01800, accuracy = 0.98047\n",
      "Epoch = 797, Batch = 429, loss = 0.00883, accuracy = 0.98047\n",
      "Epoch = 798, Batch = 429, loss = 0.00416, accuracy = 0.98047\n",
      "Epoch = 799, Batch = 429, loss = 0.00472, accuracy = 0.98047\n",
      "Epoch = 800, Batch = 429, loss = 0.00651, accuracy = 0.98047\n",
      "Epoch = 801, Batch = 429, loss = 0.03560, accuracy = 0.98047\n",
      "Epoch = 802, Batch = 429, loss = 0.00900, accuracy = 0.98047\n",
      "Epoch = 803, Batch = 429, loss = 0.00873, accuracy = 0.98047\n",
      "Epoch = 804, Batch = 429, loss = 0.01223, accuracy = 0.98047\n",
      "Epoch = 805, Batch = 429, loss = 0.00678, accuracy = 0.98047\n",
      "Epoch = 806, Batch = 429, loss = 0.00189, accuracy = 0.98047\n",
      "Epoch = 807, Batch = 429, loss = 0.00220, accuracy = 0.98047\n",
      "Epoch = 808, Batch = 429, loss = 0.00098, accuracy = 0.98047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 809, Batch = 429, loss = 0.00155, accuracy = 0.98047\n",
      "Epoch = 810, Batch = 429, loss = 0.00401, accuracy = 0.98047\n",
      "Epoch = 811, Batch = 429, loss = 0.02247, accuracy = 0.98047\n",
      "Epoch = 812, Batch = 429, loss = 0.02420, accuracy = 0.98047\n",
      "Epoch = 813, Batch = 429, loss = 0.01183, accuracy = 0.98047\n",
      "Epoch = 814, Batch = 429, loss = 0.00598, accuracy = 0.98047\n",
      "Epoch = 815, Batch = 429, loss = 0.03817, accuracy = 0.98047\n",
      "Epoch = 816, Batch = 429, loss = 0.00367, accuracy = 0.98047\n",
      "Epoch = 817, Batch = 429, loss = 0.00217, accuracy = 0.98047\n",
      "Epoch = 818, Batch = 429, loss = 0.00303, accuracy = 0.98047\n",
      "Epoch = 819, Batch = 429, loss = 0.00293, accuracy = 0.98047\n",
      "Epoch = 820, Batch = 429, loss = 0.00436, accuracy = 0.98047\n",
      "Epoch = 821, Batch = 429, loss = 0.00919, accuracy = 0.98047\n",
      "Epoch = 822, Batch = 429, loss = 0.00353, accuracy = 0.98047\n",
      "Epoch = 823, Batch = 429, loss = 0.02173, accuracy = 0.98047\n",
      "Epoch = 824, Batch = 429, loss = 0.00202, accuracy = 0.98047\n",
      "Epoch = 825, Batch = 429, loss = 0.00374, accuracy = 0.98047\n",
      "Epoch = 826, Batch = 429, loss = 0.00161, accuracy = 0.98047\n",
      "Epoch = 827, Batch = 429, loss = 0.02029, accuracy = 0.98047\n",
      "Epoch = 828, Batch = 429, loss = 0.00430, accuracy = 0.98047\n",
      "Epoch = 829, Batch = 429, loss = 0.00192, accuracy = 0.98047\n",
      "Epoch = 830, Batch = 429, loss = 0.00541, accuracy = 0.98047\n",
      "Epoch = 831, Batch = 429, loss = 0.00582, accuracy = 0.98047\n",
      "Epoch = 832, Batch = 429, loss = 0.00643, accuracy = 0.98047\n",
      "Epoch = 833, Batch = 429, loss = 0.03098, accuracy = 0.98047\n",
      "Epoch = 834, Batch = 429, loss = 0.00602, accuracy = 0.98047\n",
      "Epoch = 835, Batch = 429, loss = 0.00537, accuracy = 0.98047\n",
      "Epoch = 836, Batch = 429, loss = 0.00325, accuracy = 0.98047\n",
      "Epoch = 837, Batch = 429, loss = 0.00624, accuracy = 0.98047\n",
      "Epoch = 838, Batch = 429, loss = 0.00233, accuracy = 0.98047\n",
      "Epoch = 839, Batch = 429, loss = 0.01684, accuracy = 0.98047\n",
      "Epoch = 840, Batch = 429, loss = 0.00733, accuracy = 0.98047\n",
      "Epoch = 841, Batch = 429, loss = 0.00162, accuracy = 0.98047\n",
      "Epoch = 842, Batch = 429, loss = 0.00647, accuracy = 0.98047\n",
      "Epoch = 843, Batch = 429, loss = 0.01343, accuracy = 0.98047\n",
      "Epoch = 844, Batch = 429, loss = 0.00411, accuracy = 0.98047\n",
      "Epoch = 845, Batch = 429, loss = 0.00614, accuracy = 0.98047\n",
      "Epoch = 846, Batch = 429, loss = 0.00364, accuracy = 0.98047\n",
      "Epoch = 847, Batch = 429, loss = 0.01046, accuracy = 0.98047\n",
      "Epoch = 848, Batch = 429, loss = 0.00362, accuracy = 0.98047\n",
      "Epoch = 849, Batch = 429, loss = 0.00391, accuracy = 0.98047\n",
      "Epoch = 850, Batch = 429, loss = 0.00510, accuracy = 0.98047\n",
      "Epoch = 851, Batch = 429, loss = 0.00108, accuracy = 0.98047\n",
      "Epoch = 852, Batch = 429, loss = 0.00177, accuracy = 0.98047\n",
      "Epoch = 853, Batch = 429, loss = 0.00537, accuracy = 0.98047\n",
      "Epoch = 854, Batch = 429, loss = 0.00416, accuracy = 0.98047\n",
      "Epoch = 855, Batch = 429, loss = 0.00683, accuracy = 0.98047\n",
      "Epoch = 856, Batch = 429, loss = 0.00349, accuracy = 0.98047\n",
      "Epoch = 857, Batch = 429, loss = 0.00233, accuracy = 0.98047\n",
      "Epoch = 858, Batch = 429, loss = 0.00200, accuracy = 0.98047\n",
      "Epoch = 859, Batch = 429, loss = 0.00660, accuracy = 0.98047\n",
      "Epoch = 860, Batch = 429, loss = 0.01818, accuracy = 0.98047\n",
      "Epoch = 861, Batch = 429, loss = 0.01367, accuracy = 0.98047\n",
      "Epoch = 862, Batch = 429, loss = 0.01149, accuracy = 0.98047\n",
      "Epoch = 863, Batch = 429, loss = 0.00238, accuracy = 0.98047\n",
      "Epoch = 864, Batch = 429, loss = 0.01772, accuracy = 0.98047\n",
      "Epoch = 865, Batch = 429, loss = 0.00597, accuracy = 0.98047\n",
      "Epoch = 866, Batch = 429, loss = 0.00101, accuracy = 0.98047\n",
      "Epoch = 867, Batch = 429, loss = 0.00223, accuracy = 0.98047\n",
      "Epoch = 868, Batch = 429, loss = 0.01310, accuracy = 0.98047\n",
      "Epoch = 869, Batch = 429, loss = 0.00513, accuracy = 0.98047\n",
      "Epoch = 870, Batch = 429, loss = 0.00119, accuracy = 0.98047\n",
      "Epoch = 871, Batch = 429, loss = 0.01762, accuracy = 0.98047\n",
      "Epoch = 872, Batch = 429, loss = 0.01307, accuracy = 0.98047\n",
      "Epoch = 873, Batch = 429, loss = 0.00464, accuracy = 0.98047\n",
      "Epoch = 874, Batch = 429, loss = 0.00392, accuracy = 0.98047\n",
      "Epoch = 875, Batch = 429, loss = 0.00094, accuracy = 0.98047\n",
      "Epoch = 876, Batch = 429, loss = 0.00168, accuracy = 0.98047\n",
      "Epoch = 877, Batch = 429, loss = 0.00661, accuracy = 0.98047\n",
      "Epoch = 878, Batch = 429, loss = 0.00392, accuracy = 0.98047\n",
      "Epoch = 879, Batch = 429, loss = 0.00749, accuracy = 0.98047\n",
      "Epoch = 880, Batch = 429, loss = 0.00131, accuracy = 0.98047\n",
      "Epoch = 881, Batch = 429, loss = 0.00402, accuracy = 0.98047\n",
      "Epoch = 882, Batch = 429, loss = 0.00086, accuracy = 0.98047\n",
      "Epoch = 883, Batch = 429, loss = 0.00502, accuracy = 0.98047\n",
      "Epoch = 884, Batch = 429, loss = 0.01621, accuracy = 0.98047\n",
      "Epoch = 885, Batch = 429, loss = 0.00634, accuracy = 0.98047\n",
      "Epoch = 886, Batch = 429, loss = 0.00613, accuracy = 0.98047\n",
      "Epoch = 887, Batch = 429, loss = 0.01517, accuracy = 0.98047\n",
      "Epoch = 888, Batch = 429, loss = 0.02230, accuracy = 0.98047\n",
      "Epoch = 889, Batch = 429, loss = 0.00528, accuracy = 0.98047\n",
      "Epoch = 890, Batch = 429, loss = 0.00246, accuracy = 0.98047\n",
      "Epoch = 891, Batch = 429, loss = 0.00765, accuracy = 0.98047\n",
      "Epoch = 892, Batch = 429, loss = 0.00690, accuracy = 0.98047\n",
      "Epoch = 893, Batch = 429, loss = 0.02837, accuracy = 0.98047\n",
      "Epoch = 894, Batch = 429, loss = 0.00313, accuracy = 0.98047\n",
      "Epoch = 895, Batch = 429, loss = 0.00883, accuracy = 0.98047\n",
      "Epoch = 896, Batch = 429, loss = 0.00210, accuracy = 0.98047\n",
      "Epoch = 897, Batch = 429, loss = 0.03019, accuracy = 0.98047\n",
      "Epoch = 898, Batch = 429, loss = 0.00323, accuracy = 0.98047\n",
      "Epoch = 899, Batch = 429, loss = 0.01432, accuracy = 0.98047\n",
      "Epoch = 900, Batch = 429, loss = 0.02060, accuracy = 0.98047\n",
      "Epoch = 901, Batch = 429, loss = 0.00345, accuracy = 0.98047\n",
      "Epoch = 902, Batch = 429, loss = 0.00314, accuracy = 0.98047\n",
      "Epoch = 903, Batch = 429, loss = 0.00052, accuracy = 0.98047\n",
      "Epoch = 904, Batch = 429, loss = 0.00286, accuracy = 0.98047\n",
      "Epoch = 905, Batch = 429, loss = 0.00920, accuracy = 0.98047\n",
      "Epoch = 906, Batch = 429, loss = 0.00239, accuracy = 0.98047\n",
      "Epoch = 907, Batch = 429, loss = 0.04871, accuracy = 0.98047\n",
      "Epoch = 908, Batch = 429, loss = 0.04212, accuracy = 0.98047\n",
      "Epoch = 909, Batch = 429, loss = 0.00238, accuracy = 0.98047\n",
      "Epoch = 910, Batch = 429, loss = 0.00549, accuracy = 0.98047\n",
      "Epoch = 911, Batch = 429, loss = 0.00154, accuracy = 0.98047\n",
      "Epoch = 912, Batch = 429, loss = 0.00366, accuracy = 0.98047\n",
      "Epoch = 913, Batch = 429, loss = 0.00422, accuracy = 0.98047\n",
      "Epoch = 914, Batch = 429, loss = 0.00269, accuracy = 0.98047\n",
      "Epoch = 915, Batch = 429, loss = 0.00770, accuracy = 0.98047\n",
      "Epoch = 916, Batch = 429, loss = 0.01563, accuracy = 0.98047\n",
      "Epoch = 917, Batch = 429, loss = 0.01580, accuracy = 0.98047\n",
      "Epoch = 918, Batch = 429, loss = 0.00246, accuracy = 0.98047\n",
      "Epoch = 919, Batch = 429, loss = 0.02133, accuracy = 0.98047\n",
      "Epoch = 920, Batch = 429, loss = 0.00574, accuracy = 0.98047\n",
      "Epoch = 921, Batch = 429, loss = 0.00673, accuracy = 0.98047\n",
      "Epoch = 922, Batch = 429, loss = 0.00229, accuracy = 0.98047\n",
      "Epoch = 923, Batch = 429, loss = 0.00548, accuracy = 0.98047\n",
      "Epoch = 924, Batch = 429, loss = 0.00379, accuracy = 0.98047\n",
      "Epoch = 925, Batch = 429, loss = 0.00045, accuracy = 0.98047\n",
      "Epoch = 926, Batch = 429, loss = 0.00198, accuracy = 0.98047\n",
      "Epoch = 927, Batch = 429, loss = 0.00318, accuracy = 0.98047\n",
      "Epoch = 928, Batch = 429, loss = 0.00238, accuracy = 0.98047\n",
      "Epoch = 929, Batch = 429, loss = 0.00312, accuracy = 0.98047\n",
      "Epoch = 930, Batch = 429, loss = 0.00234, accuracy = 0.98047\n",
      "Epoch = 931, Batch = 429, loss = 0.00192, accuracy = 0.98047\n",
      "Epoch = 932, Batch = 429, loss = 0.00175, accuracy = 0.98047\n",
      "Epoch = 933, Batch = 429, loss = 0.00238, accuracy = 0.98047\n",
      "Epoch = 934, Batch = 429, loss = 0.00090, accuracy = 0.98047\n",
      "Epoch = 935, Batch = 429, loss = 0.00583, accuracy = 0.98047\n",
      "Epoch = 936, Batch = 429, loss = 0.00181, accuracy = 0.98047\n",
      "Epoch = 937, Batch = 429, loss = 0.00131, accuracy = 0.98047\n",
      "Epoch = 938, Batch = 429, loss = 0.00352, accuracy = 0.98047\n",
      "Epoch = 939, Batch = 429, loss = 0.02182, accuracy = 0.98047\n",
      "Epoch = 940, Batch = 429, loss = 0.00451, accuracy = 0.98047\n",
      "Epoch = 941, Batch = 429, loss = 0.00328, accuracy = 0.98047\n",
      "Epoch = 942, Batch = 429, loss = 0.00133, accuracy = 0.98047\n",
      "Epoch = 943, Batch = 429, loss = 0.00674, accuracy = 0.98047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 944, Batch = 429, loss = 0.00307, accuracy = 0.98047\n",
      "Epoch = 945, Batch = 429, loss = 0.00234, accuracy = 0.98047\n",
      "Epoch = 946, Batch = 429, loss = 0.00218, accuracy = 0.98047\n",
      "Epoch = 947, Batch = 429, loss = 0.00695, accuracy = 0.98047\n",
      "Epoch = 948, Batch = 429, loss = 0.00466, accuracy = 0.98047\n",
      "Epoch = 949, Batch = 429, loss = 0.00352, accuracy = 0.98047\n",
      "Epoch = 950, Batch = 429, loss = 0.00228, accuracy = 0.98047\n",
      "Epoch = 951, Batch = 429, loss = 0.00648, accuracy = 0.98047\n",
      "Epoch = 952, Batch = 429, loss = 0.00023, accuracy = 0.98047\n",
      "Epoch = 953, Batch = 429, loss = 0.00176, accuracy = 0.98047\n",
      "Epoch = 954, Batch = 429, loss = 0.00690, accuracy = 0.98047\n",
      "Epoch = 955, Batch = 429, loss = 0.00044, accuracy = 0.98047\n",
      "Epoch = 956, Batch = 429, loss = 0.00245, accuracy = 0.98047\n",
      "Epoch = 957, Batch = 429, loss = 0.00311, accuracy = 0.98047\n",
      "Epoch = 958, Batch = 429, loss = 0.01619, accuracy = 0.98047\n",
      "Epoch = 959, Batch = 429, loss = 0.00387, accuracy = 0.98047\n",
      "Epoch = 960, Batch = 429, loss = 0.00137, accuracy = 0.98047\n",
      "Epoch = 961, Batch = 429, loss = 0.00117, accuracy = 0.98047\n",
      "Epoch = 962, Batch = 429, loss = 0.00404, accuracy = 0.98047\n",
      "Epoch = 963, Batch = 429, loss = 0.00742, accuracy = 0.98047\n",
      "Epoch = 964, Batch = 429, loss = 0.00104, accuracy = 0.98047\n",
      "Epoch = 965, Batch = 429, loss = 0.00568, accuracy = 0.98047\n",
      "Epoch = 966, Batch = 429, loss = 0.00214, accuracy = 0.98047\n",
      "Epoch = 967, Batch = 429, loss = 0.00467, accuracy = 0.98047\n",
      "Epoch = 968, Batch = 429, loss = 0.00317, accuracy = 0.98047\n",
      "Epoch = 969, Batch = 429, loss = 0.00482, accuracy = 0.98047\n",
      "Epoch = 970, Batch = 429, loss = 0.00431, accuracy = 0.98047\n",
      "Epoch = 971, Batch = 429, loss = 0.02008, accuracy = 0.98047\n",
      "Epoch = 972, Batch = 429, loss = 0.00079, accuracy = 0.98047\n",
      "Epoch = 973, Batch = 429, loss = 0.00189, accuracy = 0.98047\n",
      "Epoch = 974, Batch = 429, loss = 0.00143, accuracy = 0.98047\n",
      "Epoch = 975, Batch = 429, loss = 0.00374, accuracy = 0.98047\n",
      "Epoch = 976, Batch = 429, loss = 0.00382, accuracy = 0.98047\n",
      "Epoch = 977, Batch = 429, loss = 0.00202, accuracy = 0.98047\n",
      "Epoch = 978, Batch = 429, loss = 0.00241, accuracy = 0.98047\n",
      "Epoch = 979, Batch = 429, loss = 0.00159, accuracy = 0.98047\n",
      "Epoch = 980, Batch = 429, loss = 0.00172, accuracy = 0.98047\n",
      "Epoch = 981, Batch = 429, loss = 0.00215, accuracy = 0.98047\n",
      "Epoch = 982, Batch = 429, loss = 0.00357, accuracy = 0.98047\n",
      "Epoch = 983, Batch = 429, loss = 0.00241, accuracy = 0.98047\n",
      "Epoch = 984, Batch = 429, loss = 0.00505, accuracy = 0.98047\n",
      "Epoch = 985, Batch = 429, loss = 0.11269, accuracy = 0.98047\n",
      "Epoch = 986, Batch = 429, loss = 0.00054, accuracy = 0.98047\n",
      "Epoch = 987, Batch = 429, loss = 0.02357, accuracy = 0.98047\n",
      "Epoch = 988, Batch = 429, loss = 0.00644, accuracy = 0.98047\n",
      "Epoch = 989, Batch = 429, loss = 0.00424, accuracy = 0.98047\n",
      "Epoch = 990, Batch = 429, loss = 0.01800, accuracy = 0.98047\n",
      "Epoch = 991, Batch = 429, loss = 0.00396, accuracy = 0.98047\n",
      "Epoch = 992, Batch = 429, loss = 0.02181, accuracy = 0.98047\n",
      "Epoch = 993, Batch = 429, loss = 0.00490, accuracy = 0.98047\n",
      "Epoch = 994, Batch = 429, loss = 0.00322, accuracy = 0.98047\n",
      "Epoch = 995, Batch = 429, loss = 0.00164, accuracy = 0.98047\n",
      "Epoch = 996, Batch = 429, loss = 0.01987, accuracy = 0.98047\n",
      "Epoch = 997, Batch = 429, loss = 0.00747, accuracy = 0.98047\n",
      "Epoch = 998, Batch = 429, loss = 0.00542, accuracy = 0.98047\n",
      "Epoch = 999, Batch = 429, loss = 0.00078, accuracy = 0.98047\n",
      "Epoch = 1000, Batch = 429, loss = 0.00354, accuracy = 0.98047\n",
      "fuck\n"
     ]
    }
   ],
   "source": [
    "# ========================== My own Convolutional Neural Network =========================== #\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "# Importing MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.000001\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "valid_data_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10\n",
    "dropout = 0.5\n",
    "\n",
    "# -------------------- def Xavier_initializer -------------------- #\n",
    "def Xavier_init(name, shape_in):\n",
    "    return tf.get_variable(name, shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())\n",
    "# ---------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# Store Weights & Bias\n",
    "weights = {\n",
    "    'wc1': Xavier_init('wc1',[5, 5, 1, 32]),\n",
    "    'wc2': Xavier_init('wc2',[5, 5, 32, 64]),\n",
    "    'w1' : Xavier_init('w1',[7*7*64, 1024]), # 7*7*64\n",
    "    'w2' : Xavier_init('w2',[1024, 1024]),\n",
    "    'wout': Xavier_init('wout',[1024, n_classes])\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': Xavier_init('bc1',[32]),\n",
    "    'bc2': Xavier_init('bc2',[64]),\n",
    "    'b1' : Xavier_init('b1',[1024]),\n",
    "    'b2' : Xavier_init('b2',[1024]),\n",
    "    'bout': Xavier_init('bout',[n_classes])\n",
    "}\n",
    "\n",
    "# ------------------------- defining functions ----------------------- #\n",
    "# Convolution layer\n",
    "def conv2d(x, W, b, strides=1):                                         # stride = 1\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Pooling\n",
    "def maxpool2d(x, k=2):                                                  # patch size = 2\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')\n",
    "\n",
    "# Convolution + Pooling\n",
    "def conv_net(x,weights, biases, dropout):\n",
    "    # Convolution Layer #1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Convolution Layer #2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    \n",
    "    # Hidden Layer #1\n",
    "    hl1 = tf.reshape(conv2, [-1, weights['w1'].get_shape().as_list()[0]])\n",
    "    hl1 = tf.add(tf.matmul(hl1, weights['w1']), biases['b1'])\n",
    "    hl1 = tf.nn.relu(hl1)\n",
    "    hl1 = tf.nn.dropout(hl1, dropout)\n",
    "    \n",
    "  \n",
    "    # Hidden Layer #2\n",
    "    # hl2 = tf.reshape(hl1, [-1, weights['w2'].get_shape().as_list()[0]])\n",
    "    hl2 = tf.add(tf.matmul(hl1, weights['w2']), biases['b2'])\n",
    "    hl2 = tf.nn.relu(hl2)\n",
    "    hl2 = tf.nn.dropout(hl2, dropout)\n",
    "    \n",
    "    # Output Layer\n",
    "    out = tf.add(tf.matmul(hl2, weights['wout']), biases['bout'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return out, conv1, conv2, hl1, hl2\n",
    " \n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# input & output placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob_dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# Model : output\n",
    "logits, conv1, conv2, fc1, fc2  = conv_net(x, weights, biases, keep_prob_dropout)\n",
    "\n",
    "# Define loss & Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1)) # 1???? test later\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver\n",
    "save_file = './SaveData/test1.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Training start\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # load\n",
    "    saver.restore(sess, save_file)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}) # ...? drop out?\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob_dropout: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:valid_data_size],\n",
    "                y: mnist.validation.labels[:valid_data_size],\n",
    "                keep_prob_dropout: 1.})\n",
    "            \n",
    "            \n",
    "            # for debugging\n",
    "            # print(sess.run(logits, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}))\n",
    "            # conv11, conv21, fc11, fc21 = sess.run([conv1, conv2, fc1, fc2], feed_dict = {x:batch_x, y:batch_y, keep_prob_dropout: dropout})\n",
    "            # print(sess.run(logits, feed_dict={x:batch_x, y:batch_y, keep_prob_dropout: dropout}))\n",
    "            # print(np.any(np.isinf(conv11)),np.any(np.isnan(conv11)))\n",
    "            # print(np.any(np.isinf(conv21)),np.any(np.isnan(conv21)))\n",
    "            # print(np.any(np.isinf(fc11)),np.any(np.isnan(fc11)))\n",
    "            # print(np.any(np.isinf(fc21)),np.any(np.isnan(fc21)))\n",
    "        saver.save(sess, save_file)\n",
    "        print('Epoch = {:}, Batch = {:}, loss = {:.5f}, accuracy = {:.5f}'.format(epoch+1, batch+1, loss, valid_acc))\n",
    "    print('fuck')\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4, 5, 6, np.inf])\n",
    "\n",
    "np.any(np.isinf(a))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test1.ckpt\n",
      "Weight:\n",
      "{'wc1': array([[[[  5.30384719e-01,   7.70591676e-01,   9.98935997e-01,\n",
      "            7.75745213e-01,   7.96322227e-01,  -2.85157442e-01,\n",
      "           -7.64440894e-01,  -1.70114195e+00,  -1.31222212e+00,\n",
      "            9.79790986e-01,   5.71447194e-01,  -8.49210382e-01,\n",
      "            1.35728157e+00,  -1.29976913e-01,  -3.12664938e+00,\n",
      "           -6.74573123e-01,   1.00536208e-05,  -4.65258718e-01,\n",
      "            6.57077551e-01,   8.40132296e-01,  -5.93526602e-01,\n",
      "           -3.64502132e-01,   7.89421380e-01,  -2.02460587e-01,\n",
      "           -5.97088039e-01,  -5.92503667e-01,  -4.60111231e-01,\n",
      "            5.95433235e-01,   6.71547711e-01,   6.28414035e-01,\n",
      "           -1.43515718e+00,   3.62634867e-01]],\n",
      "\n",
      "        [[ -8.53286982e-01,   2.16004562e+00,   3.26428145e-01,\n",
      "           -1.50881851e+00,  -2.46281004e+00,  -1.80430329e+00,\n",
      "           -5.44550180e-01,  -6.31653070e-01,   4.01538491e-01,\n",
      "            7.34885931e-01,   1.43191791e+00,   1.24031532e+00,\n",
      "            8.76214981e-01,  -8.73158157e-01,  -1.12996674e+00,\n",
      "            1.65929782e+00,  -1.99063003e+00,   1.28982008e+00,\n",
      "           -1.84784055e+00,  -2.21975708e+00,  -3.24622655e+00,\n",
      "            7.48585284e-01,  -2.45323563e+00,   9.01951432e-01,\n",
      "           -9.95671690e-01,  -2.14968726e-01,  -4.11556721e-01,\n",
      "           -2.08625269e+00,  -7.69011438e-01,  -2.14083719e+00,\n",
      "           -1.64666712e-01,  -1.92199759e-02]],\n",
      "\n",
      "        [[ -7.16688752e-01,   1.27871394e+00,  -2.11778188e+00,\n",
      "           -1.45130551e+00,  -8.45289409e-01,   1.23788521e-01,\n",
      "           -8.71118680e-02,   2.85577178e-01,  -2.44535804e+00,\n",
      "            2.36477897e-01,  -5.26015222e-01,   4.45972458e-02,\n",
      "           -1.30200207e+00,   2.24412352e-01,   1.60416067e+00,\n",
      "            2.53675997e-01,   5.52782655e-01,  -1.61327922e+00,\n",
      "           -6.45175517e-01,  -1.05377722e+00,  -7.92882621e-01,\n",
      "            8.65560532e-01,  -1.90157020e+00,   7.13612363e-02,\n",
      "            3.45288515e-01,   1.51082611e+00,   1.59091365e+00,\n",
      "            6.02461278e-01,  -1.49007225e+00,  -2.25194120e+00,\n",
      "            1.18497586e+00,  -3.18160951e-01]],\n",
      "\n",
      "        [[ -8.72500062e-01,  -4.04570818e-01,   6.58018887e-01,\n",
      "            1.65307307e+00,   1.16382825e+00,   5.36719441e-01,\n",
      "           -1.45185292e-01,   1.13184117e-01,   8.00327539e-01,\n",
      "           -1.32780790e+00,   2.01103425e+00,   1.27221596e+00,\n",
      "            1.44186895e-02,  -1.61323175e-01,  -9.47443068e-01,\n",
      "            1.22149080e-01,   2.51020044e-01,   1.41028002e-01,\n",
      "            8.35603476e-02,  -7.97442913e-01,   1.80842423e+00,\n",
      "            8.97384346e-01,  -8.83348942e-01,  -1.76277058e-03,\n",
      "            2.36543345e+00,  -4.66827691e-01,   1.76617348e+00,\n",
      "           -1.35928202e+00,   1.11255085e+00,   1.30533850e+00,\n",
      "            8.37152600e-01,   7.23628044e-01]],\n",
      "\n",
      "        [[  7.36739635e-01,  -6.23642147e-01,   2.60235846e-01,\n",
      "           -2.63769478e-01,  -3.79784197e-01,   1.50267780e-01,\n",
      "           -1.13786471e+00,  -5.40023208e-01,   1.36716199e+00,\n",
      "            9.12473500e-01,   6.02819145e-01,   1.40834141e+00,\n",
      "           -6.52782500e-01,   1.86553395e+00,   2.00316101e-01,\n",
      "           -8.11001599e-01,   2.22697663e+00,  -8.49479854e-01,\n",
      "            1.46614921e+00,   1.88783991e+00,  -4.93789881e-01,\n",
      "            7.63938546e-01,   4.81262565e-01,   1.17468143e+00,\n",
      "           -8.78522396e-01,  -2.72669464e-01,   1.68561304e+00,\n",
      "           -4.83650595e-01,  -1.09552872e+00,  -1.01650405e+00,\n",
      "           -7.75151670e-01,  -9.85527515e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -4.21188585e-02,   8.50834429e-01,  -1.59255314e+00,\n",
      "            1.68305361e+00,   1.70975471e+00,   1.75036049e+00,\n",
      "           -1.03723633e+00,  -5.41395366e-01,  -1.12622154e+00,\n",
      "           -1.93477607e+00,  -4.62325066e-01,  -9.50975493e-02,\n",
      "           -7.43381143e-01,   1.46919370e+00,   1.61407575e-01,\n",
      "           -2.61342734e-01,  -3.52026284e-01,  -7.56699681e-01,\n",
      "            1.03042340e+00,  -8.11458886e-01,   1.35879183e+00,\n",
      "           -4.21332121e-02,  -1.56793308e+00,   6.83743834e-01,\n",
      "            8.59508991e-01,  -1.65984428e+00,   4.64679599e-01,\n",
      "            7.88196266e-01,  -5.55610657e-01,   3.91709834e-01,\n",
      "           -7.68765509e-01,  -1.98693082e-01]],\n",
      "\n",
      "        [[ -3.41503233e-01,   7.31677830e-01,   8.49368334e-01,\n",
      "            7.63818085e-01,   1.87907010e-01,  -2.66706590e-02,\n",
      "            1.48981524e+00,  -7.88287222e-02,   8.52360845e-01,\n",
      "            3.49078327e-02,   1.80216730e+00,  -1.26277819e-01,\n",
      "           -4.25328672e-01,  -5.19663751e-01,   9.33649465e-02,\n",
      "           -5.58150351e-01,  -2.86341296e-03,   1.22560215e+00,\n",
      "           -1.11352801e+00,  -4.27558869e-01,  -7.20252097e-01,\n",
      "           -4.93353069e-01,   1.16528487e+00,  -1.20431054e+00,\n",
      "           -3.83392483e-01,   3.79960597e-01,   2.42133647e-01,\n",
      "            1.29320240e+00,   1.38849795e+00,  -1.14755392e+00,\n",
      "            1.02227688e+00,   4.99492943e-01]],\n",
      "\n",
      "        [[ -1.93250918e+00,  -8.28042850e-02,   1.59441519e+00,\n",
      "           -4.22281057e-01,   2.02046916e-01,  -1.04847113e-02,\n",
      "            2.51948327e-01,  -6.16847575e-01,  -1.45839679e+00,\n",
      "            2.76589394e-01,  -9.57055688e-01,   9.06093657e-01,\n",
      "           -2.81746358e-01,   8.21492255e-01,  -3.35398346e-01,\n",
      "           -1.32856563e-01,  -8.95152926e-01,   1.73309124e+00,\n",
      "           -1.90766394e-01,   2.21074009e+00,  -3.26240510e-01,\n",
      "            1.19903553e+00,  -3.11970651e-01,  -1.13792396e+00,\n",
      "           -1.50056303e+00,  -1.31034660e+00,  -1.45796940e-01,\n",
      "            7.05019310e-02,  -2.87460238e-01,   1.01380080e-01,\n",
      "            1.17117739e+00,   1.90454155e-01]],\n",
      "\n",
      "        [[  1.63382697e+00,   6.28704786e-01,   1.89509481e-01,\n",
      "            5.03416657e-01,  -1.65657818e+00,  -4.68720943e-01,\n",
      "            1.37959635e+00,  -1.06009746e+00,  -1.29900098e-01,\n",
      "           -8.36942196e-01,   4.22475994e-01,   1.38455534e+00,\n",
      "           -4.30389911e-01,   4.47504818e-01,   6.73034132e-01,\n",
      "            1.05876207e+00,  -1.49666727e+00,  -1.04479837e+00,\n",
      "            9.37356174e-01,   1.10851693e+00,   2.56073564e-01,\n",
      "           -6.09733999e-01,   1.28087723e+00,  -8.93775105e-01,\n",
      "            6.72109365e-01,  -8.49239901e-02,  -5.23685515e-01,\n",
      "            1.01750791e+00,  -3.31134230e-01,   5.97784162e-01,\n",
      "            7.33923793e-01,  -2.91730285e+00]],\n",
      "\n",
      "        [[ -3.90102774e-01,   1.04973972e+00,  -1.30516827e+00,\n",
      "            1.70389414e-01,  -9.20326352e-01,   3.76203448e-01,\n",
      "            4.35083181e-01,   5.63946187e-01,   1.54771006e+00,\n",
      "           -3.41145575e-01,   3.14668804e-01,  -1.24925864e+00,\n",
      "            1.19217205e+00,   1.75742793e+00,   5.49521334e-02,\n",
      "            1.16142213e+00,  -2.39119619e-01,  -2.64168344e-02,\n",
      "           -8.64594206e-02,   6.23507023e-01,  -9.28425133e-01,\n",
      "            4.66572672e-01,  -9.31642294e-01,   1.61645699e+00,\n",
      "            1.56888425e+00,  -9.68513489e-01,   9.48730171e-01,\n",
      "            1.03254151e+00,   7.73057997e-01,  -2.20728070e-01,\n",
      "           -1.15177631e+00,   1.07402217e+00]]],\n",
      "\n",
      "\n",
      "       [[[ -1.09786952e+00,   1.31394529e+00,   5.12649775e-01,\n",
      "           -5.98837137e-02,  -3.00429910e-01,  -1.38049990e-01,\n",
      "            5.49783766e-01,   1.14564621e+00,   1.84484035e-01,\n",
      "            6.26860619e-01,   1.27195859e+00,  -9.76914823e-01,\n",
      "            2.47268844e+00,  -6.50141358e-01,   9.48036611e-02,\n",
      "            7.27930665e-01,   9.76556420e-01,  -7.84307659e-01,\n",
      "           -1.43139887e+00,   7.31976405e-02,   9.19586599e-01,\n",
      "            1.04674459e+00,   1.92309737e-01,  -2.90232986e-01,\n",
      "           -5.28056264e-01,  -3.97099406e-02,   2.56372303e-01,\n",
      "            4.00140256e-01,   7.41946697e-01,   1.60061264e+00,\n",
      "           -3.98182809e-01,   1.55207813e-01]],\n",
      "\n",
      "        [[ -6.80240870e-01,   2.04914194e-02,  -8.20234776e-01,\n",
      "            2.67603278e-01,  -1.11756873e+00,  -1.41240942e+00,\n",
      "           -2.64376223e-01,  -1.60499334e+00,   1.47912598e+00,\n",
      "            4.28031981e-01,   1.69948053e+00,  -1.40840006e+00,\n",
      "            1.34121168e+00,   5.85915685e-01,  -1.42848659e+00,\n",
      "            1.70528740e-02,   4.19842809e-01,  -6.10664666e-01,\n",
      "            1.85521245e+00,   5.14450908e-01,   2.71015584e-01,\n",
      "            2.77943110e+00,   1.37389183e+00,  -2.04938579e+00,\n",
      "           -9.38003957e-01,  -1.47305250e+00,   1.29905391e+00,\n",
      "           -1.37897396e+00,   1.08805764e+00,  -1.42958319e+00,\n",
      "           -1.84896946e+00,   9.64133859e-01]],\n",
      "\n",
      "        [[  2.44117546e+00,  -1.77411032e+00,  -3.20390731e-01,\n",
      "           -1.92608431e-01,   1.23559795e-01,   9.48183611e-02,\n",
      "           -1.89079893e+00,   1.39659989e+00,  -1.62724519e+00,\n",
      "           -1.60668027e+00,   2.50479877e-01,   1.56177819e+00,\n",
      "            1.20762491e+00,  -3.76762331e-01,   1.42261863e+00,\n",
      "           -1.33324519e-01,   5.90809107e-01,  -1.40245333e-01,\n",
      "            2.84899116e-01,  -1.31147265e+00,  -1.32530773e+00,\n",
      "           -2.25256961e-02,  -1.57883191e+00,   4.88188177e-01,\n",
      "           -5.72750978e-02,   5.43690741e-01,   2.56401330e-01,\n",
      "            5.15381217e-01,   9.39034104e-01,   1.14777243e+00,\n",
      "            8.27137589e-01,   1.22463202e+00]],\n",
      "\n",
      "        [[  2.49306664e-01,  -3.31677914e-01,   3.75016451e-01,\n",
      "           -7.59586513e-01,   1.36361290e-02,  -3.41750234e-01,\n",
      "           -1.13458383e+00,   8.68515894e-02,   2.57231927e+00,\n",
      "           -3.79350543e-01,  -3.06496739e-01,  -6.32000983e-01,\n",
      "            2.38892698e+00,  -1.82271802e+00,  -9.77919996e-01,\n",
      "           -1.11307316e-01,   3.25498295e+00,  -7.16007471e-01,\n",
      "            1.68408167e+00,  -1.76989150e+00,   3.66768055e-02,\n",
      "           -7.57431388e-01,   9.57194149e-01,   1.80477142e+00,\n",
      "            2.23012529e-02,   3.88208836e-01,   1.27525401e+00,\n",
      "            1.58628941e+00,   5.62694788e-01,  -7.77804106e-02,\n",
      "            3.39080095e-01,   6.25686586e-01]],\n",
      "\n",
      "        [[  5.90594858e-02,   2.21435237e+00,  -8.10235322e-01,\n",
      "           -1.39195788e+00,   9.81882095e-01,   7.59131685e-02,\n",
      "            2.00818706e+00,  -1.17882431e+00,   4.16861475e-01,\n",
      "            1.05654514e+00,  -1.74266553e+00,   2.86411345e-01,\n",
      "           -1.35475433e+00,  -1.57541430e+00,   6.73787892e-01,\n",
      "            5.75599849e-01,   1.54278621e-01,   1.94699943e-01,\n",
      "           -5.66448808e-01,  -9.14591134e-01,  -7.76423514e-01,\n",
      "           -7.86197782e-01,  -5.79158440e-02,  -1.10028719e-03,\n",
      "            2.25770861e-01,   2.56729156e-01,   2.25355968e-01,\n",
      "           -1.06728204e-01,   7.23796934e-02,  -1.22668318e-01,\n",
      "            3.28560501e-01,  -1.58131406e-01]]],\n",
      "\n",
      "\n",
      "       [[[  1.90374506e+00,  -6.32347465e-02,   7.55327165e-01,\n",
      "            2.02563718e-01,  -7.87005499e-02,  -1.54763237e-01,\n",
      "            6.87606931e-02,   4.97613102e-01,   1.20178473e+00,\n",
      "            1.20320070e+00,  -3.02984148e-01,  -8.95599961e-01,\n",
      "            2.80935436e-01,   3.52321491e-02,  -1.26040533e-01,\n",
      "           -7.12060034e-01,  -1.65957797e+00,  -6.13711417e-01,\n",
      "           -1.41733736e-01,  -1.48779058e+00,  -9.29261267e-01,\n",
      "           -1.67791331e+00,   1.17873168e+00,  -1.54330313e+00,\n",
      "            8.26260984e-01,   3.10544968e+00,   7.81657577e-01,\n",
      "           -1.00148273e+00,   4.35862422e-01,  -4.66513813e-01,\n",
      "           -1.12717879e+00,  -4.85003173e-01]],\n",
      "\n",
      "        [[  7.38984048e-01,   6.67001724e-01,   3.12307447e-01,\n",
      "           -5.53831279e-01,  -1.30076909e+00,   4.79200065e-01,\n",
      "           -3.43020141e-01,   3.31057906e-01,   2.11956382e-01,\n",
      "            3.56382608e-01,   7.10288048e-01,   2.36363515e-01,\n",
      "            4.00938511e-01,  -4.92982626e-01,   5.49068213e-01,\n",
      "           -6.33460820e-01,  -3.88576359e-01,   1.02236795e+00,\n",
      "           -6.62084401e-01,   2.08287105e-01,   6.82766378e-01,\n",
      "           -3.19245410e+00,   6.84637547e-01,  -2.96947926e-01,\n",
      "           -8.44922423e-01,  -4.31161523e-01,   5.44829547e-01,\n",
      "            1.08142130e-01,  -1.32891163e-01,  -5.68538070e-01,\n",
      "           -3.17750096e-01,   1.75260365e+00]],\n",
      "\n",
      "        [[  7.15050638e-01,   1.22592568e+00,  -3.72653723e-01,\n",
      "           -2.02893373e-02,   6.67734325e-01,  -1.13205063e+00,\n",
      "            2.39115143e+00,   1.73700839e-01,  -3.97159994e-01,\n",
      "           -6.14748180e-01,  -2.21497798e+00,   4.56896156e-01,\n",
      "           -2.70059943e+00,   5.91852330e-03,  -4.60218906e-01,\n",
      "            1.80337977e+00,   3.94416511e-01,   6.60392046e-01,\n",
      "           -9.61530209e-01,   7.27072120e-01,   9.83503580e-01,\n",
      "            1.57763392e-01,  -5.45824051e-01,   1.24169326e+00,\n",
      "            4.96881217e-01,  -9.87216681e-02,   2.79937148e-01,\n",
      "           -1.22802043e+00,  -8.75742510e-02,   4.59565073e-01,\n",
      "            1.13896728e+00,  -2.28418231e+00]],\n",
      "\n",
      "        [[ -4.49873865e-01,  -1.78667605e-01,   1.92607909e-01,\n",
      "            4.93518859e-01,   4.39220130e-01,   1.09112990e+00,\n",
      "           -1.00084901e+00,  -5.38282275e-01,   8.43480051e-01,\n",
      "            9.75380599e-01,  -2.63811469e-01,   9.48866550e-03,\n",
      "           -8.28598380e-01,   1.56581461e+00,  -5.07324338e-01,\n",
      "            1.39382601e+00,   5.48960388e-01,   8.35569441e-01,\n",
      "           -6.10598028e-01,   6.85452759e-01,  -4.74316448e-01,\n",
      "            2.63843209e-01,   5.11090398e-01,  -1.53297770e+00,\n",
      "           -3.50108862e-01,   1.79038480e-01,  -5.51495910e-01,\n",
      "            1.27404584e-02,  -6.10069513e-01,  -3.20254266e-01,\n",
      "            4.05846119e-01,   1.04798603e+00]],\n",
      "\n",
      "        [[ -5.00342190e-01,  -2.39831612e-01,   1.36225462e+00,\n",
      "            1.10126328e+00,  -1.86268970e-01,  -2.47492477e-01,\n",
      "            4.38096002e-02,  -1.90150023e-01,  -1.41579747e-01,\n",
      "            1.16511929e+00,   7.55553842e-02,   8.25492322e-01,\n",
      "            5.14663085e-02,  -1.29710659e-01,   8.30818713e-01,\n",
      "           -5.24348855e-01,  -4.69050318e-01,   7.11945236e-01,\n",
      "           -1.03179204e+00,   2.87716448e-01,  -6.43476099e-02,\n",
      "            1.49846017e+00,   3.50166649e-01,  -9.38265622e-01,\n",
      "           -1.17036417e-01,   7.78169155e-01,   9.41776156e-01,\n",
      "           -1.70177490e-01,  -4.31548744e-01,   8.42865467e-01,\n",
      "            8.46530557e-01,   6.60209537e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -7.09728524e-02,   4.49303240e-01,   1.15425956e+00,\n",
      "            2.75249571e-01,  -5.35427272e-01,   4.71676439e-01,\n",
      "           -2.17731103e-01,  -2.14984536e+00,  -1.47703514e-01,\n",
      "           -6.95377529e-01,  -1.44977736e+00,   1.43480003e-01,\n",
      "            1.53165638e-01,   1.50298083e+00,   2.62654305e-01,\n",
      "           -6.72504604e-01,   1.95861018e+00,  -9.00327504e-01,\n",
      "           -1.09282994e+00,   3.82138222e-01,   2.55961139e-02,\n",
      "           -1.02249932e+00,  -2.99411535e-01,  -3.65015268e-01,\n",
      "            1.99882418e-01,   9.83839214e-01,   6.64986610e-01,\n",
      "            8.21691990e-01,  -1.26318224e-02,  -4.54160929e-01,\n",
      "           -2.33712479e-01,   1.03627002e+00]],\n",
      "\n",
      "        [[  7.65891850e-01,  -3.72647680e-02,   7.96927750e-01,\n",
      "           -1.05759752e+00,  -5.75774252e-01,   2.74978697e-01,\n",
      "            6.52729213e-01,  -4.27618325e-02,   2.34124947e+00,\n",
      "           -5.72286308e-01,  -1.51025081e+00,  -1.55409813e-01,\n",
      "            1.93293691e-01,   9.98861134e-01,  -1.26242578e+00,\n",
      "            1.33622825e+00,  -4.40703064e-01,  -1.67937815e+00,\n",
      "           -3.89930248e-01,   5.99138916e-01,  -4.28149730e-01,\n",
      "            7.25822151e-01,   2.53732264e-01,   3.94123971e-01,\n",
      "            1.16996574e+00,   2.87409842e-01,  -1.33594310e+00,\n",
      "            3.71962965e-01,   4.94380265e-01,  -6.50628388e-01,\n",
      "            1.97044965e-02,   9.51583013e-02]],\n",
      "\n",
      "        [[ -1.15101981e+00,  -6.44463181e-01,  -1.90570557e+00,\n",
      "           -1.27483821e+00,  -1.58391774e-01,   4.05129761e-01,\n",
      "           -5.33034921e-01,  -9.41337705e-01,  -1.04741228e+00,\n",
      "           -9.34382796e-01,  -1.06001151e+00,  -1.94639850e+00,\n",
      "           -1.25808656e+00,  -1.17277992e+00,  -5.66208303e-01,\n",
      "           -3.36345881e-01,  -2.87610114e-01,   1.79140002e-01,\n",
      "            1.41746533e+00,   3.61778796e-01,  -1.34204364e+00,\n",
      "           -6.45856917e-01,  -8.88360292e-02,  -3.96834970e-01,\n",
      "            1.65998682e-01,  -3.47175270e-01,  -6.34158909e-01,\n",
      "           -1.05278540e+00,  -6.07610166e-01,   6.70573562e-02,\n",
      "            1.82603288e+00,   8.59801173e-01]],\n",
      "\n",
      "        [[ -1.81047010e+00,   7.23856926e-01,   6.46302760e-01,\n",
      "           -5.72816849e-01,  -1.16520059e+00,   1.13489699e+00,\n",
      "           -1.27000168e-01,   8.93673122e-01,   1.73609965e-02,\n",
      "            4.66866642e-01,   6.30131960e-01,  -1.60414979e-01,\n",
      "           -7.35427022e-01,  -7.86723271e-02,  -2.07994580e+00,\n",
      "            9.97874439e-01,   1.03332353e+00,   1.05910301e+00,\n",
      "            1.30348414e-01,  -2.13816106e-01,   1.13402367e+00,\n",
      "           -1.88064551e+00,   6.40108645e-01,   1.29656804e+00,\n",
      "           -1.99164748e-01,  -5.43791413e-01,  -1.00660551e+00,\n",
      "           -4.86090571e-01,  -9.09535587e-01,   5.09522498e-01,\n",
      "            2.31114602e+00,  -1.14814627e+00]],\n",
      "\n",
      "        [[ -1.05549550e+00,   3.19025427e-01,   1.42842054e+00,\n",
      "            1.64444399e+00,   2.26928562e-01,  -2.20391464e+00,\n",
      "           -1.08840272e-01,   2.67176569e-01,  -1.82276964e+00,\n",
      "            1.45440185e+00,  -1.55943325e-02,   2.86882728e-01,\n",
      "           -2.88246199e-02,  -7.17776179e-01,   1.33318853e+00,\n",
      "            1.09864748e+00,   7.37337112e-01,   2.09864154e-01,\n",
      "           -9.24454629e-01,  -3.98898095e-01,  -7.96656013e-01,\n",
      "           -1.37088430e+00,   3.37613225e-02,  -4.62140083e-01,\n",
      "           -1.25619316e+00,  -2.13998586e-01,  -4.55029875e-01,\n",
      "           -6.75950170e-01,  -3.13837826e-01,   1.85855234e+00,\n",
      "           -8.33848715e-01,   5.47283031e-02]]]], dtype=float32), 'wc2': array([[[[  8.06723952e-01,   5.56581855e-01,   3.19468111e-01, ...,\n",
      "           -1.55340970e+00,   7.58685648e-01,   1.88264298e+00],\n",
      "         [  1.98214173e-01,  -8.63780260e-01,  -1.91404355e+00, ...,\n",
      "            1.92663446e-01,   1.37418702e-01,  -2.00840259e+00],\n",
      "         [ -2.41673604e-01,   6.25106320e-02,   1.04588902e+00, ...,\n",
      "            1.86991692e+00,  -1.06078696e+00,   3.07211667e-01],\n",
      "         ..., \n",
      "         [  1.29815146e-01,  -3.09919268e-01,   4.40942347e-01, ...,\n",
      "           -8.98174882e-01,  -4.31518704e-01,   3.72337282e-01],\n",
      "         [ -1.29667908e-01,   2.95599908e-01,   1.41401574e-01, ...,\n",
      "           -7.76004076e-01,   2.00520015e+00,  -1.78007752e-01],\n",
      "         [  2.81305599e+00,  -2.47137204e-01,   1.53183794e+00, ...,\n",
      "            1.69016445e+00,  -1.08980358e-01,   3.56631309e-01]],\n",
      "\n",
      "        [[  1.62406957e+00,  -1.27279651e+00,  -4.53988761e-01, ...,\n",
      "            7.93795943e-01,   1.27091849e+00,   1.08922875e+00],\n",
      "         [ -2.75884449e-01,   3.37908983e-01,   2.30448261e-01, ...,\n",
      "            1.65351689e+00,  -1.42130911e-01,  -4.62879427e-02],\n",
      "         [  8.43594491e-01,  -8.56746957e-02,  -1.46919489e+00, ...,\n",
      "            2.38553673e-01,  -1.12753928e-01,  -6.02977455e-01],\n",
      "         ..., \n",
      "         [  7.67991900e-01,  -5.45884192e-01,  -1.98191965e+00, ...,\n",
      "           -5.25070071e-01,   1.10464025e+00,   3.88790727e-01],\n",
      "         [ -5.84404171e-01,  -3.02771688e-01,   1.32495618e+00, ...,\n",
      "           -3.21130604e-01,   3.31162781e-01,  -1.38622761e+00],\n",
      "         [  1.09108663e+00,  -8.14321399e-01,  -2.30971146e+00, ...,\n",
      "            4.39673752e-01,  -3.52689266e-01,  -1.99437857e-01]],\n",
      "\n",
      "        [[  1.01125550e+00,  -1.56585288e+00,  -3.10403109e-02, ...,\n",
      "            1.07797556e-01,   4.58251387e-01,   2.67579269e+00],\n",
      "         [ -1.20854449e+00,  -1.22378254e+00,   2.47969046e-01, ...,\n",
      "           -3.46795440e-01,  -3.79505903e-01,   2.14787163e-02],\n",
      "         [  1.88476607e-01,  -3.11758488e-01,  -4.26645130e-01, ...,\n",
      "           -7.82883048e-01,  -1.00741243e+00,   3.07421535e-01],\n",
      "         ..., \n",
      "         [  1.07349634e+00,   6.89632118e-01,   1.22984612e+00, ...,\n",
      "            9.33667868e-02,   6.17476344e-01,  -6.75216317e-01],\n",
      "         [  1.15494955e+00,   3.82910579e-01,   3.42813349e+00, ...,\n",
      "           -2.05664039e-02,  -1.34956431e+00,  -9.66119587e-01],\n",
      "         [  4.87181991e-01,   1.18004441e+00,  -5.77642858e-01, ...,\n",
      "            1.38147891e+00,  -1.46682429e+00,  -8.89352202e-01]],\n",
      "\n",
      "        [[ -1.75050676e+00,   5.21520078e-01,  -7.11307943e-01, ...,\n",
      "            2.07936451e-01,   4.27138582e-02,   2.64640749e-01],\n",
      "         [  6.24022067e-01,   2.16857165e-01,  -1.43824071e-01, ...,\n",
      "            9.39856529e-01,  -1.70406371e-01,   6.01472318e-01],\n",
      "         [  3.18528593e-01,  -1.43081450e+00,   1.29595530e+00, ...,\n",
      "           -1.20830894e+00,  -1.38107598e+00,   1.09994638e+00],\n",
      "         ..., \n",
      "         [  7.81893134e-02,   6.34114593e-02,  -1.11028993e+00, ...,\n",
      "           -1.34645939e+00,   1.57294214e+00,   2.26039076e+00],\n",
      "         [  6.29273951e-01,   9.69925106e-01,  -4.62362528e-01, ...,\n",
      "           -9.24592555e-01,   3.32227588e-01,   3.93898815e-01],\n",
      "         [ -7.47857988e-01,  -6.71681404e-01,  -1.03942800e+00, ...,\n",
      "           -1.77005923e+00,   1.10644031e+00,   3.73124748e-01]],\n",
      "\n",
      "        [[  3.28522176e-01,  -7.12709367e-01,  -1.44812596e+00, ...,\n",
      "            3.00910687e+00,   2.59260863e-01,  -2.20099487e-03],\n",
      "         [  1.53154666e-02,  -1.26235688e+00,   1.22190881e+00, ...,\n",
      "            1.39564371e+00,  -1.25464067e-01,   1.96940809e-01],\n",
      "         [  6.54989541e-01,   5.17148435e-01,  -1.67956507e+00, ...,\n",
      "           -6.71424568e-01,   5.57195209e-02,  -7.43093967e-01],\n",
      "         ..., \n",
      "         [ -4.63663846e-01,   8.46146047e-01,   2.44244361e+00, ...,\n",
      "            5.08651853e-01,  -1.32177016e-02,   3.31070065e-01],\n",
      "         [ -9.44923818e-01,   1.05091262e+00,  -2.16323987e-01, ...,\n",
      "            2.40442705e+00,   7.64292002e-01,   8.81771624e-01],\n",
      "         [  2.36334845e-01,  -1.12540746e+00,   9.02716279e-01, ...,\n",
      "           -1.32686257e+00,   1.44925201e+00,  -1.15992880e+00]]],\n",
      "\n",
      "\n",
      "       [[[ -8.62126052e-02,  -8.25230002e-01,  -1.85279787e+00, ...,\n",
      "            3.09819245e+00,  -9.74046469e-01,  -6.96595490e-01],\n",
      "         [ -2.39937335e-01,  -3.90656352e-01,  -1.22211838e+00, ...,\n",
      "           -4.36747164e-01,   1.08719516e+00,  -9.36339140e-01],\n",
      "         [ -2.18543306e-01,  -1.07638049e+00,   2.01693296e+00, ...,\n",
      "           -5.80515862e-01,   3.34429026e-01,  -1.55928433e+00],\n",
      "         ..., \n",
      "         [  5.33017993e-01,   5.47997534e-01,  -8.61424327e-01, ...,\n",
      "           -3.70010108e-01,   1.46859372e+00,   8.23800027e-01],\n",
      "         [ -1.85717568e-01,   6.45343423e-01,  -7.55669117e-01, ...,\n",
      "            8.54215980e-01,   7.01427221e-01,   4.27231848e-01],\n",
      "         [  1.81637123e-01,  -1.62290305e-01,  -8.98214579e-01, ...,\n",
      "            1.61197209e+00,   1.11025059e+00,   2.59523362e-01]],\n",
      "\n",
      "        [[ -6.64902568e-01,   5.78524172e-01,  -4.26223963e-01, ...,\n",
      "           -1.51819599e+00,  -8.43602657e-01,  -6.35500491e-01],\n",
      "         [ -2.49084979e-01,  -9.58537698e-01,   1.08386648e+00, ...,\n",
      "            8.78608465e-01,   1.14839053e+00,  -1.03614998e+00],\n",
      "         [ -3.09307501e-02,  -8.61131310e-01,   1.12606359e+00, ...,\n",
      "           -3.76814902e-01,  -1.72241870e-02,   5.90388656e-01],\n",
      "         ..., \n",
      "         [ -1.92102268e-01,  -1.45721984e+00,  -1.04921103e+00, ...,\n",
      "           -6.75504267e-01,   5.35143495e-01,  -2.34121867e-02],\n",
      "         [ -9.14851069e-01,   6.97035015e-01,  -2.82760412e-01, ...,\n",
      "            2.43883014e+00,  -6.30451441e-02,  -1.21556390e-02],\n",
      "         [  9.88876700e-01,  -3.73959184e-01,  -4.44004178e-01, ...,\n",
      "           -6.78642452e-01,  -7.42622614e-01,   1.02535415e+00]],\n",
      "\n",
      "        [[ -2.16727734e+00,  -9.12998736e-01,  -7.36652553e-01, ...,\n",
      "            7.99989998e-01,   8.73590529e-01,  -5.27936518e-01],\n",
      "         [ -5.82443058e-01,   2.50227332e-01,  -1.04364049e+00, ...,\n",
      "            8.36010456e-01,   1.40059435e+00,   3.31250995e-01],\n",
      "         [ -2.00003251e-01,   5.16759396e-01,  -2.83366114e-01, ...,\n",
      "           -1.68975797e-02,  -5.93957424e-01,   2.42144489e+00],\n",
      "         ..., \n",
      "         [  2.07074627e-01,   6.28528893e-01,  -4.12861168e-01, ...,\n",
      "            1.46508828e-01,   9.73961413e-01,  -1.14698732e+00],\n",
      "         [  3.60046601e+00,  -2.01730227e+00,  -8.01384032e-01, ...,\n",
      "            1.57604903e-01,   9.86498117e-01,   2.75157261e+00],\n",
      "         [ -4.81953710e-01,  -3.05307768e-02,  -3.27597439e-01, ...,\n",
      "           -9.58213925e-01,   6.53841734e-01,  -1.37634850e+00]],\n",
      "\n",
      "        [[  1.00002921e+00,   8.73540699e-01,   2.40363494e-01, ...,\n",
      "           -1.06327820e+00,   7.05713749e-01,   7.18868554e-01],\n",
      "         [  5.79606235e-01,  -7.58916795e-01,   3.22704941e-01, ...,\n",
      "            6.08249843e-01,  -9.53013778e-01,   6.96344376e-01],\n",
      "         [  8.11033607e-01,  -5.47351122e-01,  -7.94168532e-01, ...,\n",
      "            1.04597151e+00,  -1.17591429e+00,   4.96105582e-01],\n",
      "         ..., \n",
      "         [ -3.87727857e-01,   1.74758244e+00,   2.25235015e-01, ...,\n",
      "           -4.30778682e-01,  -9.12675798e-01,   5.88184774e-01],\n",
      "         [ -1.87619114e+00,  -4.87999290e-01,  -5.92431962e-01, ...,\n",
      "           -2.25875306e+00,  -1.19976592e+00,  -1.33347082e+00],\n",
      "         [  2.07862401e+00,  -3.20382148e-01,   6.12395555e-02, ...,\n",
      "            5.24530947e-01,   3.40444036e-02,  -6.05910420e-01]],\n",
      "\n",
      "        [[ -2.81884558e-02,   1.25442493e+00,  -4.64426100e-01, ...,\n",
      "           -1.36428446e-01,   9.47641551e-01,  -3.33790004e-01],\n",
      "         [  3.32074106e-01,   7.59913251e-02,  -1.90391272e-01, ...,\n",
      "           -3.83218884e-01,   3.22074741e-02,   3.14280331e-01],\n",
      "         [ -7.64946401e-01,   6.73284948e-01,   1.10401487e+00, ...,\n",
      "           -4.49295640e-01,   1.38601565e+00,   1.23555720e+00],\n",
      "         ..., \n",
      "         [  9.72461283e-01,  -6.42262220e-01,  -1.16106391e+00, ...,\n",
      "            1.96236634e+00,   2.02847767e+00,   8.26961815e-01],\n",
      "         [  2.03176349e-01,   3.67931366e-01,  -2.67221093e+00, ...,\n",
      "           -1.19972479e+00,   5.15973866e-01,   1.24437916e+00],\n",
      "         [ -1.28483140e+00,  -1.60066164e+00,  -4.24741268e-01, ...,\n",
      "           -6.84810698e-01,   2.94052911e+00,   1.49851120e+00]]],\n",
      "\n",
      "\n",
      "       [[[  1.13413978e+00,   5.59329271e-01,  -8.18714857e-01, ...,\n",
      "            2.30171993e-01,   1.83510351e+00,   6.37708068e-01],\n",
      "         [ -7.47979581e-02,   2.54352379e+00,  -1.48261487e+00, ...,\n",
      "            2.47090960e+00,  -2.89165050e-01,  -8.62608790e-01],\n",
      "         [  6.83824360e-01,   1.52441382e+00,  -1.86753988e+00, ...,\n",
      "            6.83706924e-02,  -1.82944095e+00,   8.55538845e-01],\n",
      "         ..., \n",
      "         [  1.44427669e+00,  -6.06229007e-01,   8.07652831e-01, ...,\n",
      "            1.46977222e+00,  -7.77917281e-02,   8.69773149e-01],\n",
      "         [ -3.11537832e-01,   5.96124172e-01,   4.55809265e-01, ...,\n",
      "            1.62993896e+00,   9.47525561e-01,   8.25596809e-01],\n",
      "         [ -6.57459557e-01,  -1.54129621e-02,   7.41800189e-01, ...,\n",
      "           -5.67298114e-01,  -1.24712378e-01,  -2.20034170e+00]],\n",
      "\n",
      "        [[  1.91330127e-02,   3.18604261e-02,  -9.33718532e-02, ...,\n",
      "           -3.41976136e-01,  -7.39997566e-01,   2.18154684e-01],\n",
      "         [ -1.38726306e+00,  -3.97713721e-01,  -7.51818478e-01, ...,\n",
      "           -1.24754019e-01,  -1.59341961e-01,  -4.53107357e-01],\n",
      "         [ -9.27862346e-01,  -1.08391619e+00,  -1.57174456e+00, ...,\n",
      "            1.02893651e+00,  -5.30835271e-01,   4.78630513e-01],\n",
      "         ..., \n",
      "         [  1.38262665e+00,   9.31988776e-01,  -8.61246645e-01, ...,\n",
      "            1.37846076e+00,   1.32138288e+00,  -3.90322417e-01],\n",
      "         [  5.26014924e-01,   9.75108922e-01,   4.59275752e-01, ...,\n",
      "            2.52433360e-01,  -5.76281607e-01,   9.33807671e-01],\n",
      "         [ -7.86110580e-01,   7.65550554e-01,  -1.24603140e+00, ...,\n",
      "            2.25774154e-01,   2.68850654e-01,   3.03666770e-01]],\n",
      "\n",
      "        [[ -7.17362583e-01,  -1.44464886e+00,  -2.47274208e+00, ...,\n",
      "           -6.16870761e-01,   1.69973040e+00,  -6.28355220e-02],\n",
      "         [  1.21724689e+00,   1.83815467e+00,  -1.51955143e-01, ...,\n",
      "            1.31163919e+00,   2.44385570e-01,  -2.04909420e+00],\n",
      "         [ -6.77346587e-01,   1.45889473e+00,  -6.61894798e-01, ...,\n",
      "           -5.75025976e-01,   1.59849852e-01,   6.26526058e-01],\n",
      "         ..., \n",
      "         [  1.84564874e-01,  -4.88372624e-01,   2.89617956e-01, ...,\n",
      "           -1.35498643e+00,   1.42603898e+00,   3.71205866e-01],\n",
      "         [  1.21325505e+00,  -4.64697778e-01,   4.55034494e-01, ...,\n",
      "            1.72110438e+00,   1.31546628e+00,   6.82158828e-01],\n",
      "         [  3.90980989e-01,   4.32956904e-01,   8.22712660e-01, ...,\n",
      "           -3.86929922e-02,   1.06778514e+00,  -1.13636434e+00]],\n",
      "\n",
      "        [[  4.73634869e-01,   1.31125069e+00,  -2.24971104e+00, ...,\n",
      "           -3.62983346e-01,  -3.17204475e+00,   8.51558074e-02],\n",
      "         [  4.29221779e-01,  -2.43088412e+00,   1.20390284e+00, ...,\n",
      "            1.25657630e+00,  -5.15026271e-01,  -8.40838253e-01],\n",
      "         [ -1.78269374e+00,   4.78043020e-01,   1.19035232e+00, ...,\n",
      "           -1.72358677e-01,   3.14835048e+00,   1.05511689e+00],\n",
      "         ..., \n",
      "         [ -9.81586576e-01,  -6.76909864e-01,  -1.20503962e-01, ...,\n",
      "            2.48143688e-01,  -1.69850454e-01,  -7.17709482e-01],\n",
      "         [ -5.30246973e-01,  -1.10564840e+00,  -1.12333465e+00, ...,\n",
      "           -4.70031828e-01,  -3.13908570e-02,  -9.93708313e-01],\n",
      "         [ -2.00943637e+00,  -2.66774446e-01,  -2.34842211e-01, ...,\n",
      "           -1.26427650e-01,  -8.33580554e-01,  -1.08472109e+00]],\n",
      "\n",
      "        [[ -8.22260976e-01,   4.54057872e-01,  -1.03059971e+00, ...,\n",
      "            5.57003319e-01,  -3.18732381e-01,   1.32771969e+00],\n",
      "         [ -1.80383384e-01,   1.31788039e+00,  -8.18853736e-01, ...,\n",
      "            2.05440474e+00,  -2.36464977e+00,   1.70154965e+00],\n",
      "         [ -4.87165958e-01,  -8.65944147e-01,  -4.90438163e-01, ...,\n",
      "            3.31238776e-01,  -1.22206128e+00,   2.17576456e+00],\n",
      "         ..., \n",
      "         [  8.29625547e-01,   9.39995944e-02,  -8.16685259e-01, ...,\n",
      "           -7.98532888e-02,  -3.55751179e-02,   2.79147118e-01],\n",
      "         [ -7.89444149e-01,   9.30532634e-01,  -5.79219699e-01, ...,\n",
      "           -7.65021980e-01,   2.12130046e+00,  -4.90823835e-01],\n",
      "         [ -5.03412366e-01,   3.95619571e-01,   1.07705235e+00, ...,\n",
      "            1.44197762e+00,  -5.65822482e-01,   6.05040602e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.03954744e+00,  -1.12540662e+00,   4.15437855e-02, ...,\n",
      "           -2.67735571e-01,   1.12184870e+00,   9.08075050e-02],\n",
      "         [ -1.23444544e-02,   3.07999969e-01,   8.14349949e-01, ...,\n",
      "           -7.63225853e-02,  -8.76887023e-01,  -1.48560226e+00],\n",
      "         [  9.85078156e-01,   7.61105269e-02,   2.15716195e+00, ...,\n",
      "            1.52121723e+00,  -3.51098388e-01,  -1.99817741e+00],\n",
      "         ..., \n",
      "         [  2.17679524e+00,  -1.14146066e+00,  -4.52649593e-02, ...,\n",
      "            5.83841622e-01,   1.45706975e+00,  -9.23431575e-01],\n",
      "         [ -5.90998590e-01,  -4.44422305e-01,  -8.19751084e-01, ...,\n",
      "           -1.10636544e+00,  -1.64816153e+00,  -3.55277508e-01],\n",
      "         [  1.37819660e+00,  -2.20794287e-02,  -8.35371673e-01, ...,\n",
      "            7.64846921e-01,  -2.84340334e+00,  -7.45484173e-01]],\n",
      "\n",
      "        [[ -9.53742564e-01,  -9.82902884e-01,  -2.87397027e-01, ...,\n",
      "            2.08115011e-01,  -1.94914669e-01,  -2.14914486e-01],\n",
      "         [  6.76233709e-01,  -9.30787697e-02,   8.34226310e-01, ...,\n",
      "           -3.32083046e-01,   4.98709768e-01,   8.18907559e-01],\n",
      "         [  3.71958941e-01,  -7.12871909e-01,   1.89491713e+00, ...,\n",
      "           -6.17211103e-01,  -1.13981104e+00,  -2.56608784e-01],\n",
      "         ..., \n",
      "         [ -1.01327324e+00,   2.32892230e-01,  -4.10002053e-01, ...,\n",
      "            5.37573934e-01,  -1.16855025e+00,  -3.23922896e+00],\n",
      "         [  2.17354894e+00,   8.14496636e-01,   9.22322571e-01, ...,\n",
      "           -1.41574490e+00,  -4.06000584e-01,   2.70823747e-01],\n",
      "         [  2.74496108e-01,   8.86730194e-01,   1.06020950e-01, ...,\n",
      "           -7.14928329e-01,   4.80724007e-01,  -1.93654633e+00]],\n",
      "\n",
      "        [[ -4.45121199e-01,  -1.44550754e-02,   8.89432579e-02, ...,\n",
      "           -2.79804796e-01,  -1.06629884e+00,  -5.10142565e-01],\n",
      "         [ -8.60026300e-01,   1.52341500e-01,   1.83402240e+00, ...,\n",
      "           -8.42300296e-01,  -1.17413187e+00,   5.03377914e-01],\n",
      "         [ -2.35627845e-01,  -2.73587584e-01,  -7.51217782e-01, ...,\n",
      "           -8.08383226e-01,   9.27402079e-01,   2.47511670e-01],\n",
      "         ..., \n",
      "         [  6.80247605e-01,   1.07468057e+00,  -1.21544674e-01, ...,\n",
      "            1.28291464e+00,   2.55781323e-01,   2.00117302e+00],\n",
      "         [ -2.43269652e-01,   1.32870233e+00,   1.04060188e-01, ...,\n",
      "           -6.68411016e-01,  -1.01961255e+00,   1.17722225e+00],\n",
      "         [ -1.62891853e+00,  -7.35838711e-01,   1.14543426e+00, ...,\n",
      "            1.70124257e+00,   1.97670460e-01,  -2.48424038e-01]],\n",
      "\n",
      "        [[ -3.67529780e-01,  -1.00345802e+00,   2.07028461e+00, ...,\n",
      "            2.85018444e-01,   1.77957892e-01,  -9.82634500e-02],\n",
      "         [  9.71857667e-01,  -1.75482422e-01,   1.10484374e+00, ...,\n",
      "            7.40891337e-01,   2.47141227e-01,   2.30116081e+00],\n",
      "         [  7.34019041e-01,   1.08299255e+00,  -4.06291746e-02, ...,\n",
      "            6.04396164e-01,  -3.06925118e-01,  -1.04233098e+00],\n",
      "         ..., \n",
      "         [ -1.01029181e+00,   5.63379049e-01,  -3.97120953e-01, ...,\n",
      "            1.72569120e+00,   1.06438851e+00,  -9.61662084e-02],\n",
      "         [  1.23504543e+00,   9.81360793e-01,   8.30916464e-01, ...,\n",
      "           -1.60655475e+00,  -8.53688776e-01,   4.40170556e-01],\n",
      "         [  2.50744200e+00,  -1.14830387e+00,  -3.50140959e-01, ...,\n",
      "            3.71744156e-01,   1.83893549e+00,  -1.16223097e+00]],\n",
      "\n",
      "        [[  6.52488768e-01,  -4.57367897e-01,   4.10081416e-01, ...,\n",
      "            1.04763234e+00,   1.01378226e+00,  -8.06640565e-01],\n",
      "         [ -5.64552248e-01,  -1.84982210e-01,   2.73271585e+00, ...,\n",
      "           -8.10761452e-01,  -5.93826115e-01,   5.60970247e-01],\n",
      "         [  1.52448738e+00,   1.71973690e-01,  -1.90548658e-01, ...,\n",
      "           -8.70347679e-01,  -4.04292375e-01,  -1.21428239e+00],\n",
      "         ..., \n",
      "         [ -1.76726353e+00,  -4.61976469e-01,  -2.83208460e-01, ...,\n",
      "            8.42420161e-01,  -6.03248060e-01,  -2.01922870e+00],\n",
      "         [ -2.28890944e+00,   1.09961659e-01,  -9.74168360e-01, ...,\n",
      "            1.06996726e-02,   2.10103646e-01,   7.17611492e-01],\n",
      "         [  1.63489748e-02,  -1.60062879e-01,  -1.82428416e-02, ...,\n",
      "           -1.34005427e+00,   9.31670070e-01,  -2.46243015e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.80765346e-01,  -1.11824656e+00,  -4.67022508e-01, ...,\n",
      "            4.40423936e-01,   4.24526781e-01,   4.20234874e-02],\n",
      "         [  1.66695923e-01,   6.76093459e-01,  -4.14955616e-01, ...,\n",
      "            1.63832828e-01,  -2.60225683e-01,  -3.05823493e+00],\n",
      "         [  6.75831020e-01,  -6.00802362e-01,   1.91251472e-01, ...,\n",
      "            1.46898484e+00,   7.63983369e-01,   2.22957587e+00],\n",
      "         ..., \n",
      "         [  8.99516940e-02,  -9.54736173e-01,  -8.15420449e-02, ...,\n",
      "            5.00186026e-01,  -4.63165849e-01,  -6.15406156e-01],\n",
      "         [  1.87034041e-01,   8.07010889e-01,  -7.09270611e-02, ...,\n",
      "            2.06883574e+00,   9.40796977e-04,  -1.13860512e+00],\n",
      "         [ -2.35547948e+00,   5.54704368e-01,  -4.07324374e-01, ...,\n",
      "            1.55333832e-01,   1.74730456e+00,   5.09907126e-01]],\n",
      "\n",
      "        [[ -9.30426180e-01,  -9.28187609e-01,   3.45956266e-01, ...,\n",
      "           -4.31262195e-01,  -8.14000890e-02,   8.04544210e-01],\n",
      "         [  8.18506002e-01,  -1.04084826e+00,   1.10150111e+00, ...,\n",
      "           -1.01315737e+00,   7.44159341e-01,  -8.93377423e-01],\n",
      "         [  1.51577950e+00,   2.63804525e-01,   2.34927356e-01, ...,\n",
      "            6.50896132e-02,   1.48516738e+00,  -1.19396496e+00],\n",
      "         ..., \n",
      "         [  3.26097369e-01,  -1.49141939e-03,  -1.22593367e+00, ...,\n",
      "            1.30202532e+00,  -1.80892006e-01,   9.85294223e-01],\n",
      "         [ -1.23975015e+00,  -1.19911575e+00,  -1.74584222e+00, ...,\n",
      "            3.38927412e+00,   6.74778894e-02,  -3.06162179e-01],\n",
      "         [  4.65816259e-01,  -7.31548667e-01,   6.87655091e-01, ...,\n",
      "           -5.06685197e-01,  -4.80684757e-01,   1.65379748e-01]],\n",
      "\n",
      "        [[  1.69944537e+00,   1.39875746e+00,   2.33726382e-01, ...,\n",
      "            1.18176055e+00,  -4.48806912e-01,  -9.04996514e-01],\n",
      "         [  1.34184778e+00,  -2.05869985e+00,   5.05806386e-01, ...,\n",
      "            5.62968493e-01,  -1.41966724e+00,   4.27403510e-01],\n",
      "         [ -9.25367355e-01,  -7.65599310e-01,   3.11896741e-01, ...,\n",
      "           -4.79006737e-01,  -3.49957764e-01,  -2.81054795e-01],\n",
      "         ..., \n",
      "         [ -4.80870996e-03,  -3.46859068e-01,   1.44772276e-01, ...,\n",
      "            1.65569484e+00,  -2.22665425e-02,   1.25025022e+00],\n",
      "         [  1.60786724e+00,  -1.38574094e-01,  -1.00131679e+00, ...,\n",
      "            4.64264601e-01,   1.56837201e+00,  -1.78870678e-01],\n",
      "         [  1.12944111e-01,   1.16213214e+00,   1.63674235e+00, ...,\n",
      "            3.35343957e-01,  -3.92857999e-01,  -6.14965498e-01]],\n",
      "\n",
      "        [[ -1.51567304e+00,  -9.57265317e-01,  -1.17785776e+00, ...,\n",
      "           -7.78628290e-01,  -8.47840786e-01,  -4.73039001e-01],\n",
      "         [  9.93932426e-01,  -1.23553443e+00,   1.13534987e+00, ...,\n",
      "            6.63517356e-01,  -5.05586922e-01,   1.11609077e+00],\n",
      "         [ -6.33234084e-01,   1.02876222e+00,  -3.84550579e-02, ...,\n",
      "           -3.76126525e-04,   1.53586185e+00,   4.23915803e-01],\n",
      "         ..., \n",
      "         [  2.22317073e-02,   1.34964120e+00,   2.01043391e+00, ...,\n",
      "            4.58941832e-02,  -8.39189470e-01,   1.76815236e+00],\n",
      "         [ -1.31987345e+00,   1.23529173e-02,  -1.78511351e-01, ...,\n",
      "            3.61183614e-01,   1.20619273e+00,   1.37579954e+00],\n",
      "         [ -1.49403840e-01,   4.35787708e-01,   2.52582461e-01, ...,\n",
      "           -1.10888660e+00,  -4.87443000e-01,  -1.10483490e-01]],\n",
      "\n",
      "        [[ -8.56098346e-03,   8.66059661e-01,  -5.95013499e-01, ...,\n",
      "            6.87482208e-02,   2.79376531e+00,   3.13445568e-01],\n",
      "         [  1.00766075e+00,   2.24537969e+00,  -5.05959153e-01, ...,\n",
      "            7.87022710e-01,   1.28013849e-01,   1.00843251e+00],\n",
      "         [ -3.09512198e-01,   7.58066952e-01,   3.37600499e-01, ...,\n",
      "           -1.57772565e+00,   1.71903580e-01,  -7.58892179e-01],\n",
      "         ..., \n",
      "         [  1.54628800e-02,   5.11868715e-01,   2.74080932e-01, ...,\n",
      "            7.51692727e-02,   1.34167182e+00,  -6.54592454e-01],\n",
      "         [  7.36068428e-01,  -4.49974030e-01,   1.67787945e+00, ...,\n",
      "            1.61874473e+00,   5.26959300e-01,   1.27866721e+00],\n",
      "         [ -4.68617797e-01,  -1.49029493e+00,   1.89694464e+00, ...,\n",
      "           -1.81922364e+00,   8.05337846e-01,   7.12746233e-02]]]], dtype=float32), 'w1': array([[ 0.22643179, -1.51759732,  0.24250685, ..., -0.84166801,\n",
      "         0.64392716,  2.46203709],\n",
      "       [ 0.0652922 , -0.26930049, -0.54206157, ...,  2.85966682,\n",
      "        -0.12134494,  0.39558738],\n",
      "       [ 0.90477389, -0.55736315, -1.37286615, ..., -0.63245213,\n",
      "        -0.60977346, -1.95427263],\n",
      "       ..., \n",
      "       [-0.01021127, -0.77358419, -0.44385487, ...,  0.39264023,\n",
      "        -0.22084363,  1.50873923],\n",
      "       [ 0.28039297,  0.5347361 ,  1.1369493 , ..., -0.14548525,\n",
      "        -0.366945  , -1.55145764],\n",
      "       [ 1.15329862, -0.90224957, -0.90180326, ...,  2.28321242,\n",
      "         1.17154789,  0.57811069]], dtype=float32), 'w2': array([[ 0.09479874,  0.84976232,  1.15429878, ..., -1.02732968,\n",
      "        -0.84425825, -1.23027062],\n",
      "       [ 1.24176562,  0.3371878 ,  0.45556188, ..., -0.24382035,\n",
      "         0.86575216,  0.07220551],\n",
      "       [ 1.53133535,  1.41018772,  1.26608443, ...,  1.05357194,\n",
      "        -0.13968347, -0.00339406],\n",
      "       ..., \n",
      "       [-0.53131175,  0.78290105,  0.53096527, ...,  0.53273547,\n",
      "        -0.91794401, -0.7022981 ],\n",
      "       [ 0.2315259 ,  0.99057692,  0.92647171, ...,  0.80427134,\n",
      "         0.38995594,  0.44531897],\n",
      "       [ 0.22193117, -0.00597406, -0.544025  , ..., -1.17071295,\n",
      "         0.85413635, -0.75533605]], dtype=float32), 'out': array([[ 1.25760829, -1.05432558, -2.0521524 , ..., -0.10278005,\n",
      "        -0.49251083, -0.05879743],\n",
      "       [ 1.80301154, -0.33205855,  0.21563366, ...,  0.26424652,\n",
      "        -1.8100152 ,  0.13616216],\n",
      "       [-0.65224069,  0.77797186,  0.79548556, ...,  0.33382022,\n",
      "        -0.55835652, -1.21709013],\n",
      "       ..., \n",
      "       [ 0.51946414, -0.26924273, -0.55619574, ..., -0.60906541,\n",
      "         0.42133489, -0.66565496],\n",
      "       [ 0.17219822,  2.07416725, -0.322788  , ..., -0.69202793,\n",
      "        -0.18687095, -1.52419651],\n",
      "       [-1.34523964, -1.94541347, -1.449893  , ..., -1.4739784 ,\n",
      "         0.06346636, -1.97662079]], dtype=float32)}\n",
      "Bias:\n",
      "{'bc1': array([ 0.17048645,  1.7547977 ,  0.59083718, -0.70702875, -1.19010329,\n",
      "        0.18581197, -1.82183456,  1.28887486,  0.21186744, -0.95443439,\n",
      "        0.82637787, -0.17246889,  1.44408071,  0.21366642,  0.14456698,\n",
      "        3.81334901,  0.96160114, -1.58919859, -0.45643425,  0.58179647,\n",
      "        1.74756229,  0.79718739, -2.19983387,  0.05903302, -0.07366935,\n",
      "        0.01552122,  0.35429141, -1.3292942 , -1.4553591 ,  0.74672878,\n",
      "       -1.00692689, -0.30222294], dtype=float32), 'bc2': array([-1.29789507,  0.75378019,  0.78458691,  1.20544541, -0.275354  ,\n",
      "        1.9714607 , -0.48046616,  0.19845334,  0.41519433,  0.91210228,\n",
      "        0.19832817,  0.52384424,  0.01387061,  0.49451452, -0.64545161,\n",
      "        1.61358237, -0.03887851, -0.81013352,  0.44571516, -0.84198785,\n",
      "        0.80939049, -0.70276678,  1.17190242,  1.81581724,  1.2563839 ,\n",
      "        2.31242681,  1.65913618, -0.48966408,  0.53128672,  0.99447274,\n",
      "        0.14295734, -0.19971809,  2.50463843, -0.81256318,  1.1379751 ,\n",
      "        0.03985387,  0.29247797, -0.5968045 , -0.06701593,  1.11452162,\n",
      "        1.48000968,  0.47063425, -1.18825388, -1.47768688, -0.93519527,\n",
      "       -2.27593613,  0.65040582, -0.11173488, -1.0452292 , -0.37351397,\n",
      "        0.4495326 ,  1.58191299, -0.86705142,  0.64804095, -0.77863795,\n",
      "       -0.15942687,  0.41458541,  0.10668072,  0.14351635,  0.57070905,\n",
      "        0.9883548 ,  2.37319326, -0.46824005,  0.41256857], dtype=float32), 'b1': array([ 1.48251438,  0.01521228, -1.26346707, ...,  2.05605531,\n",
      "       -1.14886439, -0.33529982], dtype=float32), 'b2': array([ 1.00643766,  0.72728944,  0.3366234 , ...,  1.07977057,\n",
      "        0.92807251,  0.95498836], dtype=float32), 'out': array([ 1.07624352,  0.22242475,  0.48769498,  0.42261896, -2.14672661,\n",
      "        0.8863616 ,  0.90536386, -0.7316013 , -1.75633669,  0.34624931], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loading\n",
    "import tensorflow as tf\n",
    "# Remove the previous weights and bias\n",
    "n_classes = 10\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "# weights = tf.Variable(tf.truncated_normal([2, 3]), name = 'weight_1')\n",
    "# bias = tf.Variable(tf.truncated_normal([3]), name = 'bias_1')\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'w1' : tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'w2' : tf.Variable(tf.random_normal([1024, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'b1' : tf.Variable(tf.random_normal([1024])),\n",
    "    'b2' : tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "save_file = './test1.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "    \n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(biases))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
